{"cells":[{"cell_type":"markdown","source":"# Back Propagation","metadata":{"tags":[],"cell_id":"00000-5f78143d-679e-4a7a-bcee-e45d303c8077","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"In order to understand backpropagation, you will implement a backpropagation algorithm for a neural network from scratch. <br/>\nBackpropagation can be used for both classification and regression problems, we will focus on classification in\nthis exercise.","metadata":{"tags":[],"cell_id":"00001-546b7283-e5fc-4964-b909-05999d8e1ec6","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"#### Exercise 1 : initialization of the network","metadata":{"tags":[],"cell_id":"00001-66f7130d-30c8-494b-97b6-9ff954019de3","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00002-b3805151-a572-44dd-80e3-9bf1bbf40d88","deepnote_to_be_reexecuted":false,"source_hash":"f3593c6b","execution_millis":3,"execution_start":1612396855878,"deepnote_cell_type":"code"},"source":"from random import random, seed, shuffle","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00000-8e43e9fe-04af-44f8-8f02-6fa857e730f1","deepnote_to_be_reexecuted":false,"source_hash":"1f82172f","execution_millis":3,"execution_start":1612396855891,"deepnote_cell_type":"code"},"source":"def init_network(n_inputs, n_hidden, n_outputs): \n    network = list()\n\n    # hidden layer \n    hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n    network.append(hidden_layer)\n\n    # output layer \n    output_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n    network.append(output_layer)\n\n    return network\n","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Exercise 2 : ","metadata":{"tags":[],"cell_id":"00004-622067b8-b20d-40f8-bf9a-ef4e2ad3efb3","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00004-4e4dee39-07bb-4e69-8ec1-3b1ea1f323ea","deepnote_to_be_reexecuted":false,"source_hash":"2c84c44a","execution_millis":33,"execution_start":1612396855896,"deepnote_cell_type":"code"},"source":"seed(1)\nnet = init_network(2,4,6)\nfor layer in net: \n    print(layer)","execution_count":null,"outputs":[{"name":"stdout","text":"[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}, {'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381]}, {'weights': [0.651592972722763, 0.7887233511355132, 0.0938595867742349]}, {'weights': [0.02834747652200631, 0.8357651039198697, 0.43276706790505337]}]\n[{'weights': [0.762280082457942, 0.0021060533511106927, 0.4453871940548014, 0.7215400323407826, 0.22876222127045265]}, {'weights': [0.9452706955539223, 0.9014274576114836, 0.030589983033553536, 0.0254458609934608, 0.5414124727934966]}, {'weights': [0.9391491627785106, 0.38120423768821243, 0.21659939713061338, 0.4221165755827173, 0.029040787574867943]}, {'weights': [0.22169166627303505, 0.43788759365057206, 0.49581224138185065, 0.23308445025757263, 0.2308665415409843]}, {'weights': [0.2187810373376886, 0.4596034657377336, 0.28978161459048557, 0.021489705265908876, 0.8375779756625729]}, {'weights': [0.5564543226524334, 0.6422943629324456, 0.1859062658947177, 0.9925434121760651, 0.8599465287952899]}]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Forward Propagation","metadata":{"tags":[],"cell_id":"00006-07fab1f8-351b-4b46-9260-5702d6d0da8e","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"#### Exercise 3 : Neuron activation","metadata":{"tags":[],"cell_id":"00006-9b51756f-dc4b-48f9-95b5-7045f7d94902","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00007-c0d29e90-e1f0-4325-9264-12efcfd1fed1","deepnote_to_be_reexecuted":false,"source_hash":"9b0853fa","execution_millis":0,"execution_start":1612396855922,"deepnote_cell_type":"code"},"source":"# Weight is a network weight\n# Input is an input (can be line of a dataset, should be a vector of the same size of the number of nodes in the network)\n# Bias is a special weight that has no input to multiply with\n\n# activation = sum(weight_i * input_i) + bias","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00008-6e0d634a-c91a-477d-a01f-3753da1070e4","deepnote_to_be_reexecuted":false,"source_hash":"ddb23fec","execution_millis":1,"execution_start":1612396855922,"deepnote_cell_type":"code"},"source":"# weights is a list of given weights\n# inputs is a list of inputs\n\ndef activate(weights, inputs): \n    # To simplify, the bias = the last weight of weights\n    activation = weights[-1]\n    for i in range(len(weights) - 1): \n        activation += weights[i] * inputs[i]\n    return activation","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Exercise 4 : Neuron transfer","metadata":{"tags":[],"cell_id":"00009-9279a548-189e-4af9-919c-8f69f75ccec3","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00009-5865f3b7-dcdc-473d-84c4-b21d4af7955b","deepnote_to_be_reexecuted":false,"source_hash":"fbd7384f","execution_millis":1,"execution_start":1612396855923,"deepnote_cell_type":"code"},"source":"from math import exp\n\ndef transfer(activation): \n    return 1.0/(1.0 + exp(-activation))","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Exercise 5 : Forward propagation","metadata":{"tags":[],"cell_id":"00011-c3e1b22c-9a27-4497-b519-5935b14fd769","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00012-745815f0-164b-4a5e-99ad-a2b0b96394d3","deepnote_to_be_reexecuted":false,"source_hash":"cc4844d8","execution_millis":4,"execution_start":1612396855932,"deepnote_cell_type":"code"},"source":"# Forward propagate input to a network output\ndef forward_propagate(network, row): \n    inputs = row\n    for layer in network: \n        new_inputs = []\n        for neuron in layer: \n            activation = activate(neuron['weights'], inputs)\n            neuron['output'] = transfer(activation)\n            new_inputs.append(neuron['output'])\n        inputs = new_inputs\n    return inputs","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Exercise 6 : Testing our forward propagation","metadata":{"tags":[],"cell_id":"00013-cf2458ca-6300-4d95-bc6a-7b4f91f15f76","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00014-9add10a2-8f60-4a00-8a8b-7c8264ed1515","deepnote_to_be_reexecuted":false,"source_hash":"ee98be86","execution_millis":14,"execution_start":1612396855947,"deepnote_cell_type":"code"},"source":"seed(1)\nnetwork = init_network(3, 2, 2)\nrow = [1, 0, 0]\noutput = forward_propagate(network, row)\n\noutput","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"[0.7138015773148616, 0.7020509238862008]"},"metadata":{}}]},{"cell_type":"markdown","source":"### Back Propagation Error","metadata":{"tags":[],"cell_id":"00017-3b940bd9-0bcc-446f-a984-ceade42e98c4","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"#### Exercise 7 : Transfer derivative","metadata":{"tags":[],"cell_id":"00016-5d937f11-894f-4d2b-b174-9d445cb8d64c","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00016-c2c6b07c-cf84-4785-990a-983466861179","deepnote_to_be_reexecuted":false,"source_hash":"46a71456","execution_millis":1,"execution_start":1612396855956,"deepnote_cell_type":"code"},"source":"# if transfer function is sigmoid \ndef transfer_derivative(output): \n    return output * (1.0 - output)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Exercise 8 : Error Backpropagation","metadata":{"tags":[],"cell_id":"00020-6e555376-b072-447d-8cb7-247c73546d2d","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00021-4eaa3ef8-3a95-4d35-8fbf-3adaec794c5c","deepnote_to_be_reexecuted":false,"source_hash":"41fd2fa1","execution_millis":8,"execution_start":1612396855957,"deepnote_cell_type":"code"},"source":"# error = (expected - output) * transfer_derivative(output)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00022-37d80270-e8ae-4342-9258-ba7764f2847a","deepnote_to_be_reexecuted":false,"source_hash":"7bc3ea14","execution_millis":8,"execution_start":1612396855967,"deepnote_cell_type":"code"},"source":"# Backpropagate error and store in neurons\ndef backward_propagate_error(network, expected): \n    for i in reversed(range(len(network))): \n        layer = network[i]\n        errors = list()\n        if i != len(network) - 1 : \n            for j in range(len(layer)): \n                error = 0.0\n                for neuron in network[i+1]: \n                    error += (neuron['weights'][j] * neuron['delta'])\n                errors.append(error)\n        else: \n            for j in range(len(layer)): \n                neuron = layer[j]\n                errors.append(expected[j] - neuron['output'])\n        for j in range(len(layer)): \n            neuron = layer[j]\n            neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Exercise 9 : Test backward propagate error","metadata":{"tags":[],"cell_id":"00023-87c0ec95-81ce-4b1b-9123-85efd3e9582b","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00023-e7e900a5-678e-49fe-9066-b783fbed0df7","deepnote_to_be_reexecuted":false,"source_hash":"1484205","execution_millis":2,"execution_start":1612396855978,"deepnote_cell_type":"code"},"source":"expected = [0.7138015773148616, 0.7020509238862008]\nbackward_propagate_error(network, expected)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00024-62fef57a-24a0-4deb-8faa-b2b48c264666","deepnote_to_be_reexecuted":false,"source_hash":"fab8db4","execution_millis":32,"execution_start":1612396856039,"deepnote_cell_type":"code"},"source":"network","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"[[{'weights': [0.13436424411240122,\n    0.8474337369372327,\n    0.763774618976614,\n    0.2550690257394217],\n   'output': 0.5961462631100435,\n   'delta': 0.0},\n  {'weights': [0.49543508709194095,\n    0.4494910647887381,\n    0.651592972722763,\n    0.7887233511355132],\n   'output': 0.7831568031528053,\n   'delta': 0.0}],\n [{'weights': [0.0938595867742349, 0.02834747652200631, 0.8357651039198697],\n   'output': 0.7138015773148616,\n   'delta': 0.0},\n  {'weights': [0.43276706790505337, 0.762280082457942, 0.0021060533511106927],\n   'output': 0.7020509238862008,\n   'delta': 0.0}]]"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Exercise 10 : Update weights","metadata":{"tags":[],"cell_id":"00026-9c1d0661-ac1c-413a-ba6a-8c6bdbda1ca0","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00027-2abe1bc5-1ce4-48ce-bc95-021dd5a83f9a","deepnote_to_be_reexecuted":false,"source_hash":"46f42894","execution_millis":0,"execution_start":1612396856040,"deepnote_cell_type":"code"},"source":"# weight = weight + learning rate * error * input","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"where **weight** is a given weight, <br/>\n**learning rate** is a parameter that you must\nspecify, <br/>\n**error** is the error calculated by the backpropagation procedure for the\nneuron and <br/>\n**input** is the input value that caused the error.","metadata":{"tags":[],"cell_id":"00028-2a7b81a1-78df-4d0a-994d-363783e3df93","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00028-dabff4d6-892e-43ed-9646-0bb12b74ae48","deepnote_to_be_reexecuted":false,"source_hash":"cd5d48","execution_millis":0,"execution_start":1612396856040,"deepnote_cell_type":"code"},"source":"def update_weights(network, row, l_rate):\n\tfor i in range(len(network)):\n\t\tinputs = row[:-1]\n\t\tif i != 0:\n\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n\t\tfor neuron in network[i]:\n\t\t\tfor j in range(len(inputs)):\n\t\t\t\tneuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n\t\t\tneuron['weights'][-1] += l_rate * neuron['delta']","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Exercise 11 : Train network","metadata":{"tags":[],"cell_id":"00030-5930a904-0b83-45a3-9268-7fcf5c08cf02","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00031-e55802b1-98dc-4945-8120-6b76bc5ede8d","deepnote_to_be_reexecuted":false,"source_hash":"8f00531e","execution_millis":2,"execution_start":1612396856076,"deepnote_cell_type":"code"},"source":"def train_network(network, train, l_rate, n_epoch, n_outputs):\n\tfor epoch in range(n_epoch):\n\t\tsum_error = 0\n\t\tfor row in train:\n\t\t\toutputs = forward_propagate(network, row)\n\t\t\texpected = [0 for i in range(n_outputs)]\n\t\t\texpected[row[-1]] = 1\n\t\t\tsum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n\t\t\tbackward_propagate_error(network, expected)\n\t\t\tupdate_weights(network, row, l_rate)\n\t\tprint('> epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Exercise 12 : Define a dataset and test","metadata":{"tags":[],"cell_id":"00032-3a4d5bdb-e9cd-4f3e-acba-c96397443bfb","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00033-aa7fef61-7305-4579-af63-46381f5897b1","deepnote_to_be_reexecuted":false,"source_hash":"3b9b0e41","execution_millis":0,"execution_start":1612396856077,"deepnote_cell_type":"code"},"source":"dataset = [[2.7810836,2.550537003,0],\n\t[1.465489372,2.362125076,0],\n\t[3.396561688,4.400293529,0],\n\t[1.38807019,1.850220317,0],\n\t[3.06407232,3.005305973,0],\n\t[7.627531214,2.759262235,1],\n\t[5.332441248,2.088626775,1],\n\t[6.922596716,1.77106367,1],\n\t[8.675418651,-0.242068655,1],\n\t[7.673756466,3.508563011,1]]","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00034-65915231-2592-4ddf-ae71-12a8c08877c9","deepnote_to_be_reexecuted":false,"source_hash":"70eac874","execution_millis":45,"execution_start":1612396856077,"deepnote_cell_type":"code"},"source":"seed(1)\nn_inputs = len(dataset[0]) - 1\nn_outputs = len(set([row[-1] for row in dataset]))\nnetwork = init_network(n_inputs, 2, n_outputs)\ntrain_network(network, dataset, 0.5, 20, n_outputs)\nfor layer in network:\n\tprint(layer)","execution_count":null,"outputs":[{"name":"stdout","text":"> epoch=0, lrate=0.500, error=6.350\n> epoch=1, lrate=0.500, error=5.531\n> epoch=2, lrate=0.500, error=5.221\n> epoch=3, lrate=0.500, error=4.951\n> epoch=4, lrate=0.500, error=4.519\n> epoch=5, lrate=0.500, error=4.173\n> epoch=6, lrate=0.500, error=3.835\n> epoch=7, lrate=0.500, error=3.506\n> epoch=8, lrate=0.500, error=3.192\n> epoch=9, lrate=0.500, error=2.898\n> epoch=10, lrate=0.500, error=2.626\n> epoch=11, lrate=0.500, error=2.377\n> epoch=12, lrate=0.500, error=2.153\n> epoch=13, lrate=0.500, error=1.953\n> epoch=14, lrate=0.500, error=1.774\n> epoch=15, lrate=0.500, error=1.614\n> epoch=16, lrate=0.500, error=1.472\n> epoch=17, lrate=0.500, error=1.346\n> epoch=18, lrate=0.500, error=1.233\n> epoch=19, lrate=0.500, error=1.132\n[{'weights': [-1.4688375095432327, 1.850887325439514, 1.0858178629550297], 'output': 0.029980305604426185, 'delta': -0.0059546604162323625}, {'weights': [0.37711098142462157, -0.0625909894552989, 0.2765123702642716], 'output': 0.9456229000211323, 'delta': 0.0026279652850863837}]\n[{'weights': [2.515394649397849, -0.3391927502445985, -0.9671565426390275], 'output': 0.23648794202357587, 'delta': -0.04270059278364587}, {'weights': [-2.5584149848484263, 1.0036422106209202, 0.42383086467582715], 'output': 0.7790535202438367, 'delta': 0.03803132596437354}]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Exercise 13 : Predict","metadata":{"tags":[],"cell_id":"00035-ad507c62-17db-4249-b140-3cae6ffc5f7b","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00035-252da5a7-3805-4566-8a95-c67b9dccbebc","deepnote_to_be_reexecuted":false,"source_hash":"cce70734","execution_millis":0,"execution_start":1612396856091,"deepnote_cell_type":"code"},"source":"def predict(network, row):\n\toutputs = forward_propagate(network, row)\n\treturn outputs.index(max(outputs))","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Exercise 14 : Test the prediction","metadata":{"tags":[],"cell_id":"00037-d8da183a-a8a2-438d-a844-edf3596e977e","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00037-dc42f4f2-4435-4a58-b275-ab5cb611bcdb","deepnote_to_be_reexecuted":false,"source_hash":"4addb7a8","execution_millis":21,"execution_start":1612396856101,"deepnote_cell_type":"code"},"source":"for row in dataset:\n\tprediction = predict(network, row)\n\tprint('Expected=%d, Got=%d' % (row[-1], prediction))","execution_count":null,"outputs":[{"name":"stdout","text":"Expected=0, Got=0\nExpected=0, Got=0\nExpected=0, Got=0\nExpected=0, Got=0\nExpected=0, Got=0\nExpected=1, Got=1\nExpected=1, Got=1\nExpected=1, Got=1\nExpected=1, Got=1\nExpected=1, Got=1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Exercise 15 and 16 : Import dataset","metadata":{"tags":[],"cell_id":"00039-b4dd3fb6-2b19-410a-ad1b-496f8b1bab39","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00040-b8532598-5688-4117-a19a-6e54f5e333ff","deepnote_to_be_reexecuted":false,"source_hash":"1470ce46","execution_millis":51,"execution_start":1612396856111,"deepnote_cell_type":"code"},"source":"import csv\ndef load_csv(filename):\n\tdataset = list()\n\twith open(filename, 'r') as file:\n\t\tcsv_reader = csv.reader(file)\n\t\tfor row in csv_reader:\n\t\t\tif not row:\n\t\t\t\tcontinue\n\t\t\tdataset.append(row)\n\t\t\t\n\tfor row in range(len(dataset)): \n\t\tdataset[row] = dataset[row][0].split('\\t')\n\t\tfor i in range(len(dataset[row])): \n\t\t\tdataset[row][i] = float(dataset[row][i].strip())\n\treturn dataset","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00044-82ae6f9d-7f74-4c60-9d09-5598aa442fce","deepnote_to_be_reexecuted":false,"source_hash":"efb11634","execution_millis":6,"execution_start":1612396856148,"deepnote_cell_type":"code"},"source":"seed(1)\ndataset = load_csv('seeds_dataset.csv')\ndataset","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"[[15.26, 14.84, 0.871, 5.763, 3.312, 2.221, 5.22, 1.0],\n [14.88, 14.57, 0.8811, 5.554, 3.333, 1.018, 4.956, 1.0],\n [14.29, 14.09, 0.905, 5.291, 3.337, 2.699, 4.825, 1.0],\n [13.84, 13.94, 0.8955, 5.324, 3.379, 2.259, 4.805, 1.0],\n [16.14, 14.99, 0.9034, 5.658, 3.562, 1.355, 5.175, 1.0],\n [14.38, 14.21, 0.8951, 5.386, 3.312, 2.462, 4.956, 1.0],\n [14.69, 14.49, 0.8799, 5.563, 3.259, 3.586, 5.219, 1.0],\n [14.11, 14.1, 0.8911, 5.42, 3.302, 2.7, 5.0, 1.0],\n [16.63, 15.46, 0.8747, 6.053, 3.465, 2.04, 5.877, 1.0],\n [16.44, 15.25, 0.888, 5.884, 3.505, 1.969, 5.533, 1.0],\n [15.26, 14.85, 0.8696, 5.714, 3.242, 4.543, 5.314, 1.0],\n [14.03, 14.16, 0.8796, 5.438, 3.201, 1.717, 5.001, 1.0],\n [13.89, 14.02, 0.888, 5.439, 3.199, 3.986, 4.738, 1.0],\n [13.78, 14.06, 0.8759, 5.479, 3.156, 3.136, 4.872, 1.0],\n [13.74, 14.05, 0.8744, 5.482, 3.114, 2.932, 4.825, 1.0],\n [14.59, 14.28, 0.8993, 5.351, 3.333, 4.185, 4.781, 1.0],\n [13.99, 13.83, 0.9183, 5.119, 3.383, 5.234, 4.781, 1.0],\n [15.69, 14.75, 0.9058, 5.527, 3.514, 1.599, 5.046, 1.0],\n [14.7, 14.21, 0.9153, 5.205, 3.466, 1.767, 4.649, 1.0],\n [12.72, 13.57, 0.8686, 5.226, 3.049, 4.102, 4.914, 1.0],\n [14.16, 14.4, 0.8584, 5.658, 3.129, 3.072, 5.176, 1.0],\n [14.11, 14.26, 0.8722, 5.52, 3.168, 2.688, 5.219, 1.0],\n [15.88, 14.9, 0.8988, 5.618, 3.507, 0.7651, 5.091, 1.0],\n [12.08, 13.23, 0.8664, 5.099, 2.936, 1.415, 4.961, 1.0],\n [15.01, 14.76, 0.8657, 5.789, 3.245, 1.791, 5.001, 1.0],\n [16.19, 15.16, 0.8849, 5.833, 3.421, 0.903, 5.307, 1.0],\n [13.02, 13.76, 0.8641, 5.395, 3.026, 3.373, 4.825, 1.0],\n [12.74, 13.67, 0.8564, 5.395, 2.956, 2.504, 4.869, 1.0],\n [14.11, 14.18, 0.882, 5.541, 3.221, 2.754, 5.038, 1.0],\n [13.45, 14.02, 0.8604, 5.516, 3.065, 3.531, 5.097, 1.0],\n [13.16, 13.82, 0.8662, 5.454, 2.975, 0.8551, 5.056, 1.0],\n [15.49, 14.94, 0.8724, 5.757, 3.371, 3.412, 5.228, 1.0],\n [14.09, 14.41, 0.8529, 5.717, 3.186, 3.92, 5.299, 1.0],\n [13.94, 14.17, 0.8728, 5.585, 3.15, 2.124, 5.012, 1.0],\n [15.05, 14.68, 0.8779, 5.712, 3.328, 2.129, 5.36, 1.0],\n [16.12, 15.0, 0.9, 5.709, 3.485, 2.27, 5.443, 1.0],\n [16.2, 15.27, 0.8734, 5.826, 3.464, 2.823, 5.527, 1.0],\n [17.08, 15.38, 0.9079, 5.832, 3.683, 2.956, 5.484, 1.0],\n [14.8, 14.52, 0.8823, 5.656, 3.288, 3.112, 5.309, 1.0],\n [14.28, 14.17, 0.8944, 5.397, 3.298, 6.685, 5.001, 1.0],\n [13.54, 13.85, 0.8871, 5.348, 3.156, 2.587, 5.178, 1.0],\n [13.5, 13.85, 0.8852, 5.351, 3.158, 2.249, 5.176, 1.0],\n [13.16, 13.55, 0.9009, 5.138, 3.201, 2.461, 4.783, 1.0],\n [15.5, 14.86, 0.882, 5.877, 3.396, 4.711, 5.528, 1.0],\n [15.11, 14.54, 0.8986, 5.579, 3.462, 3.128, 5.18, 1.0],\n [13.8, 14.04, 0.8794, 5.376, 3.155, 1.56, 4.961, 1.0],\n [15.36, 14.76, 0.8861, 5.701, 3.393, 1.367, 5.132, 1.0],\n [14.99, 14.56, 0.8883, 5.57, 3.377, 2.958, 5.175, 1.0],\n [14.79, 14.52, 0.8819, 5.545, 3.291, 2.704, 5.111, 1.0],\n [14.86, 14.67, 0.8676, 5.678, 3.258, 2.129, 5.351, 1.0],\n [14.43, 14.4, 0.8751, 5.585, 3.272, 3.975, 5.144, 1.0],\n [15.78, 14.91, 0.8923, 5.674, 3.434, 5.593, 5.136, 1.0],\n [14.49, 14.61, 0.8538, 5.715, 3.113, 4.116, 5.396, 1.0],\n [14.33, 14.28, 0.8831, 5.504, 3.199, 3.328, 5.224, 1.0],\n [14.52, 14.6, 0.8557, 5.741, 3.113, 1.481, 5.487, 1.0],\n [15.03, 14.77, 0.8658, 5.702, 3.212, 1.933, 5.439, 1.0],\n [14.46, 14.35, 0.8818, 5.388, 3.377, 2.802, 5.044, 1.0],\n [14.92, 14.43, 0.9006, 5.384, 3.412, 1.142, 5.088, 1.0],\n [15.38, 14.77, 0.8857, 5.662, 3.419, 1.999, 5.222, 1.0],\n [12.11, 13.47, 0.8392, 5.159, 3.032, 1.502, 4.519, 1.0],\n [11.42, 12.86, 0.8683, 5.008, 2.85, 2.7, 4.607, 1.0],\n [11.23, 12.63, 0.884, 4.902, 2.879, 2.269, 4.703, 1.0],\n [12.36, 13.19, 0.8923, 5.076, 3.042, 3.22, 4.605, 1.0],\n [13.22, 13.84, 0.868, 5.395, 3.07, 4.157, 5.088, 1.0],\n [12.78, 13.57, 0.8716, 5.262, 3.026, 1.176, 4.782, 1.0],\n [12.88, 13.5, 0.8879, 5.139, 3.119, 2.352, 4.607, 1.0],\n [14.34, 14.37, 0.8726, 5.63, 3.19, 1.313, 5.15, 1.0],\n [14.01, 14.29, 0.8625, 5.609, 3.158, 2.217, 5.132, 1.0],\n [14.37, 14.39, 0.8726, 5.569, 3.153, 1.464, 5.3, 1.0],\n [12.73, 13.75, 0.8458, 5.412, 2.882, 3.533, 5.067, 1.0],\n [17.63, 15.98, 0.8673, 6.191, 3.561, 4.076, 6.06, 2.0],\n [16.84, 15.67, 0.8623, 5.998, 3.484, 4.675, 5.877, 2.0],\n [17.26, 15.73, 0.8763, 5.978, 3.594, 4.539, 5.791, 2.0],\n [19.11, 16.26, 0.9081, 6.154, 3.93, 2.936, 6.079, 2.0],\n [16.82, 15.51, 0.8786, 6.017, 3.486, 4.004, 5.841, 2.0],\n [16.77, 15.62, 0.8638, 5.927, 3.438, 4.92, 5.795, 2.0],\n [17.32, 15.91, 0.8599, 6.064, 3.403, 3.824, 5.922, 2.0],\n [20.71, 17.23, 0.8763, 6.579, 3.814, 4.451, 6.451, 2.0],\n [18.94, 16.49, 0.875, 6.445, 3.639, 5.064, 6.362, 2.0],\n [17.12, 15.55, 0.8892, 5.85, 3.566, 2.858, 5.746, 2.0],\n [16.53, 15.34, 0.8823, 5.875, 3.467, 5.532, 5.88, 2.0],\n [18.72, 16.19, 0.8977, 6.006, 3.857, 5.324, 5.879, 2.0],\n [20.2, 16.89, 0.8894, 6.285, 3.864, 5.173, 6.187, 2.0],\n [19.57, 16.74, 0.8779, 6.384, 3.772, 1.472, 6.273, 2.0],\n [19.51, 16.71, 0.878, 6.366, 3.801, 2.962, 6.185, 2.0],\n [18.27, 16.09, 0.887, 6.173, 3.651, 2.443, 6.197, 2.0],\n [18.88, 16.26, 0.8969, 6.084, 3.764, 1.649, 6.109, 2.0],\n [18.98, 16.66, 0.859, 6.549, 3.67, 3.691, 6.498, 2.0],\n [21.18, 17.21, 0.8989, 6.573, 4.033, 5.78, 6.231, 2.0],\n [20.88, 17.05, 0.9031, 6.45, 4.032, 5.016, 6.321, 2.0],\n [20.1, 16.99, 0.8746, 6.581, 3.785, 1.955, 6.449, 2.0],\n [18.76, 16.2, 0.8984, 6.172, 3.796, 3.12, 6.053, 2.0],\n [18.81, 16.29, 0.8906, 6.272, 3.693, 3.237, 6.053, 2.0],\n [18.59, 16.05, 0.9066, 6.037, 3.86, 6.001, 5.877, 2.0],\n [18.36, 16.52, 0.8452, 6.666, 3.485, 4.933, 6.448, 2.0],\n [16.87, 15.65, 0.8648, 6.139, 3.463, 3.696, 5.967, 2.0],\n [19.31, 16.59, 0.8815, 6.341, 3.81, 3.477, 6.238, 2.0],\n [18.98, 16.57, 0.8687, 6.449, 3.552, 2.144, 6.453, 2.0],\n [18.17, 16.26, 0.8637, 6.271, 3.512, 2.853, 6.273, 2.0],\n [18.72, 16.34, 0.881, 6.219, 3.684, 2.188, 6.097, 2.0],\n [16.41, 15.25, 0.8866, 5.718, 3.525, 4.217, 5.618, 2.0],\n [17.99, 15.86, 0.8992, 5.89, 3.694, 2.068, 5.837, 2.0],\n [19.46, 16.5, 0.8985, 6.113, 3.892, 4.308, 6.009, 2.0],\n [19.18, 16.63, 0.8717, 6.369, 3.681, 3.357, 6.229, 2.0],\n [18.95, 16.42, 0.8829, 6.248, 3.755, 3.368, 6.148, 2.0],\n [18.83, 16.29, 0.8917, 6.037, 3.786, 2.553, 5.879, 2.0],\n [18.85, 16.17, 0.9056, 6.152, 3.806, 2.843, 6.2, 2.0],\n [17.63, 15.86, 0.88, 6.033, 3.573, 3.747, 5.929, 2.0],\n [19.94, 16.92, 0.8752, 6.675, 3.763, 3.252, 6.55, 2.0],\n [18.55, 16.22, 0.8865, 6.153, 3.674, 1.738, 5.894, 2.0],\n [18.45, 16.12, 0.8921, 6.107, 3.769, 2.235, 5.794, 2.0],\n [19.38, 16.72, 0.8716, 6.303, 3.791, 3.678, 5.965, 2.0],\n [19.13, 16.31, 0.9035, 6.183, 3.902, 2.109, 5.924, 2.0],\n [19.14, 16.61, 0.8722, 6.259, 3.737, 6.682, 6.053, 2.0],\n [20.97, 17.25, 0.8859, 6.563, 3.991, 4.677, 6.316, 2.0],\n [19.06, 16.45, 0.8854, 6.416, 3.719, 2.248, 6.163, 2.0],\n [18.96, 16.2, 0.9077, 6.051, 3.897, 4.334, 5.75, 2.0],\n [19.15, 16.45, 0.889, 6.245, 3.815, 3.084, 6.185, 2.0],\n [18.89, 16.23, 0.9008, 6.227, 3.769, 3.639, 5.966, 2.0],\n [20.03, 16.9, 0.8811, 6.493, 3.857, 3.063, 6.32, 2.0],\n [20.24, 16.91, 0.8897, 6.315, 3.962, 5.901, 6.188, 2.0],\n [18.14, 16.12, 0.8772, 6.059, 3.563, 3.619, 6.011, 2.0],\n [16.17, 15.38, 0.8588, 5.762, 3.387, 4.286, 5.703, 2.0],\n [18.43, 15.97, 0.9077, 5.98, 3.771, 2.984, 5.905, 2.0],\n [15.99, 14.89, 0.9064, 5.363, 3.582, 3.336, 5.144, 2.0],\n [18.75, 16.18, 0.8999, 6.111, 3.869, 4.188, 5.992, 2.0],\n [18.65, 16.41, 0.8698, 6.285, 3.594, 4.391, 6.102, 2.0],\n [17.98, 15.85, 0.8993, 5.979, 3.687, 2.257, 5.919, 2.0],\n [20.16, 17.03, 0.8735, 6.513, 3.773, 1.91, 6.185, 2.0],\n [17.55, 15.66, 0.8991, 5.791, 3.69, 5.366, 5.661, 2.0],\n [18.3, 15.89, 0.9108, 5.979, 3.755, 2.837, 5.962, 2.0],\n [18.94, 16.32, 0.8942, 6.144, 3.825, 2.908, 5.949, 2.0],\n [15.38, 14.9, 0.8706, 5.884, 3.268, 4.462, 5.795, 2.0],\n [16.16, 15.33, 0.8644, 5.845, 3.395, 4.266, 5.795, 2.0],\n [15.56, 14.89, 0.8823, 5.776, 3.408, 4.972, 5.847, 2.0],\n [15.38, 14.66, 0.899, 5.477, 3.465, 3.6, 5.439, 2.0],\n [17.36, 15.76, 0.8785, 6.145, 3.574, 3.526, 5.971, 2.0],\n [15.57, 15.15, 0.8527, 5.92, 3.231, 2.64, 5.879, 2.0],\n [15.6, 15.11, 0.858, 5.832, 3.286, 2.725, 5.752, 2.0],\n [16.23, 15.18, 0.885, 5.872, 3.472, 3.769, 5.922, 2.0],\n [13.07, 13.92, 0.848, 5.472, 2.994, 5.304, 5.395, 3.0],\n [13.32, 13.94, 0.8613, 5.541, 3.073, 7.035, 5.44, 3.0],\n [13.34, 13.95, 0.862, 5.389, 3.074, 5.995, 5.307, 3.0],\n [12.22, 13.32, 0.8652, 5.224, 2.967, 5.469, 5.221, 3.0],\n [11.82, 13.4, 0.8274, 5.314, 2.777, 4.471, 5.178, 3.0],\n [11.21, 13.13, 0.8167, 5.279, 2.687, 6.169, 5.275, 3.0],\n [11.43, 13.13, 0.8335, 5.176, 2.719, 2.221, 5.132, 3.0],\n [12.49, 13.46, 0.8658, 5.267, 2.967, 4.421, 5.002, 3.0],\n [12.7, 13.71, 0.8491, 5.386, 2.911, 3.26, 5.316, 3.0],\n [10.79, 12.93, 0.8107, 5.317, 2.648, 5.462, 5.194, 3.0],\n [11.83, 13.23, 0.8496, 5.263, 2.84, 5.195, 5.307, 3.0],\n [12.01, 13.52, 0.8249, 5.405, 2.776, 6.992, 5.27, 3.0],\n [12.26, 13.6, 0.8333, 5.408, 2.833, 4.756, 5.36, 3.0],\n [11.18, 13.04, 0.8266, 5.22, 2.693, 3.332, 5.001, 3.0],\n [11.36, 13.05, 0.8382, 5.175, 2.755, 4.048, 5.263, 3.0],\n [11.19, 13.05, 0.8253, 5.25, 2.675, 5.813, 5.219, 3.0],\n [11.34, 12.87, 0.8596, 5.053, 2.849, 3.347, 5.003, 3.0],\n [12.13, 13.73, 0.8081, 5.394, 2.745, 4.825, 5.22, 3.0],\n [11.75, 13.52, 0.8082, 5.444, 2.678, 4.378, 5.31, 3.0],\n [11.49, 13.22, 0.8263, 5.304, 2.695, 5.388, 5.31, 3.0],\n [12.54, 13.67, 0.8425, 5.451, 2.879, 3.082, 5.491, 3.0],\n [12.02, 13.33, 0.8503, 5.35, 2.81, 4.271, 5.308, 3.0],\n [12.05, 13.41, 0.8416, 5.267, 2.847, 4.988, 5.046, 3.0],\n [12.55, 13.57, 0.8558, 5.333, 2.968, 4.419, 5.176, 3.0],\n [11.14, 12.79, 0.8558, 5.011, 2.794, 6.388, 5.049, 3.0],\n [12.1, 13.15, 0.8793, 5.105, 2.941, 2.201, 5.056, 3.0],\n [12.44, 13.59, 0.8462, 5.319, 2.897, 4.924, 5.27, 3.0],\n [12.15, 13.45, 0.8443, 5.417, 2.837, 3.638, 5.338, 3.0],\n [11.35, 13.12, 0.8291, 5.176, 2.668, 4.337, 5.132, 3.0],\n [11.24, 13.0, 0.8359, 5.09, 2.715, 3.521, 5.088, 3.0],\n [11.02, 13.0, 0.8189, 5.325, 2.701, 6.735, 5.163, 3.0],\n [11.55, 13.1, 0.8455, 5.167, 2.845, 6.715, 4.956, 3.0],\n [11.27, 12.97, 0.8419, 5.088, 2.763, 4.309, 5.0, 3.0],\n [11.4, 13.08, 0.8375, 5.136, 2.763, 5.588, 5.089, 3.0],\n [10.83, 12.96, 0.8099, 5.278, 2.641, 5.182, 5.185, 3.0],\n [10.8, 12.57, 0.859, 4.981, 2.821, 4.773, 5.063, 3.0],\n [11.26, 13.01, 0.8355, 5.186, 2.71, 5.335, 5.092, 3.0],\n [10.74, 12.73, 0.8329, 5.145, 2.642, 4.702, 4.963, 3.0],\n [11.48, 13.05, 0.8473, 5.18, 2.758, 5.876, 5.002, 3.0],\n [12.21, 13.47, 0.8453, 5.357, 2.893, 1.661, 5.178, 3.0],\n [11.41, 12.95, 0.856, 5.09, 2.775, 4.957, 4.825, 3.0],\n [12.46, 13.41, 0.8706, 5.236, 3.017, 4.987, 5.147, 3.0],\n [12.19, 13.36, 0.8579, 5.24, 2.909, 4.857, 5.158, 3.0],\n [11.65, 13.07, 0.8575, 5.108, 2.85, 5.209, 5.135, 3.0],\n [12.89, 13.77, 0.8541, 5.495, 3.026, 6.185, 5.316, 3.0],\n [11.56, 13.31, 0.8198, 5.363, 2.683, 4.062, 5.182, 3.0],\n [11.81, 13.45, 0.8198, 5.413, 2.716, 4.898, 5.352, 3.0],\n [10.91, 12.8, 0.8372, 5.088, 2.675, 4.179, 4.956, 3.0],\n [11.23, 12.82, 0.8594, 5.089, 2.821, 7.524, 4.957, 3.0],\n [10.59, 12.41, 0.8648, 4.899, 2.787, 4.975, 4.794, 3.0],\n [10.93, 12.8, 0.839, 5.046, 2.717, 5.398, 5.045, 3.0],\n [11.27, 12.86, 0.8563, 5.091, 2.804, 3.985, 5.001, 3.0],\n [11.87, 13.02, 0.8795, 5.132, 2.953, 3.597, 5.132, 3.0],\n [10.82, 12.83, 0.8256, 5.18, 2.63, 4.853, 5.089, 3.0],\n [12.11, 13.27, 0.8639, 5.236, 2.975, 4.132, 5.012, 3.0],\n [12.8, 13.47, 0.886, 5.16, 3.126, 4.873, 4.914, 3.0],\n [12.79, 13.53, 0.8786, 5.224, 3.054, 5.483, 4.958, 3.0],\n [13.37, 13.78, 0.8849, 5.32, 3.128, 4.67, 5.091, 3.0],\n [12.62, 13.67, 0.8481, 5.41, 2.911, 3.306, 5.231, 3.0],\n [12.76, 13.38, 0.8964, 5.073, 3.155, 2.828, 4.83, 3.0],\n [12.38, 13.44, 0.8609, 5.219, 2.989, 5.472, 5.045, 3.0],\n [12.67, 13.32, 0.8977, 4.984, 3.135, 2.3, 4.745, 3.0],\n [11.18, 12.72, 0.868, 5.009, 2.81, 4.051, 4.828, 3.0],\n [12.7, 13.41, 0.8874, 5.183, 3.091, 8.456, 5.0, 3.0],\n [12.37, 13.47, 0.8567, 5.204, 2.96, 3.919, 5.001, 3.0],\n [12.19, 13.2, 0.8783, 5.137, 2.981, 3.631, 4.87, 3.0],\n [11.23, 12.88, 0.8511, 5.14, 2.795, 4.325, 5.003, 3.0],\n [13.2, 13.66, 0.8883, 5.236, 3.232, 8.315, 5.056, 3.0],\n [11.84, 13.21, 0.8521, 5.175, 2.836, 3.598, 5.044, 3.0],\n [12.3, 13.34, 0.8684, 5.243, 2.974, 5.637, 5.063, 3.0]]"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Exercise 17 : Shuffle dataset and normalize columns","metadata":{"tags":[],"cell_id":"00045-3bd7eb57-40d9-4cff-944a-b8acef3966ef","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00046-b9426915-25cc-4a85-a9c8-7edba76ffee3","deepnote_to_be_reexecuted":false,"source_hash":"e3ef1a96","execution_millis":49,"execution_start":1612396856170,"deepnote_cell_type":"code"},"source":"shuffle(dataset)\ndataset","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"[[14.92, 14.43, 0.9006, 5.384, 3.412, 1.142, 5.088, 1.0],\n [18.98, 16.66, 0.859, 6.549, 3.67, 3.691, 6.498, 2.0],\n [18.94, 16.32, 0.8942, 6.144, 3.825, 2.908, 5.949, 2.0],\n [12.02, 13.33, 0.8503, 5.35, 2.81, 4.271, 5.308, 3.0],\n [18.88, 16.26, 0.8969, 6.084, 3.764, 1.649, 6.109, 2.0],\n [12.05, 13.41, 0.8416, 5.267, 2.847, 4.988, 5.046, 3.0],\n [12.46, 13.41, 0.8706, 5.236, 3.017, 4.987, 5.147, 3.0],\n [13.74, 14.05, 0.8744, 5.482, 3.114, 2.932, 4.825, 1.0],\n [19.14, 16.61, 0.8722, 6.259, 3.737, 6.682, 6.053, 2.0],\n [14.8, 14.52, 0.8823, 5.656, 3.288, 3.112, 5.309, 1.0],\n [16.12, 15.0, 0.9, 5.709, 3.485, 2.27, 5.443, 1.0],\n [17.32, 15.91, 0.8599, 6.064, 3.403, 3.824, 5.922, 2.0],\n [18.81, 16.29, 0.8906, 6.272, 3.693, 3.237, 6.053, 2.0],\n [11.02, 13.0, 0.8189, 5.325, 2.701, 6.735, 5.163, 3.0],\n [12.72, 13.57, 0.8686, 5.226, 3.049, 4.102, 4.914, 1.0],\n [16.2, 15.27, 0.8734, 5.826, 3.464, 2.823, 5.527, 1.0],\n [10.93, 12.8, 0.839, 5.046, 2.717, 5.398, 5.045, 3.0],\n [18.55, 16.22, 0.8865, 6.153, 3.674, 1.738, 5.894, 2.0],\n [16.53, 15.34, 0.8823, 5.875, 3.467, 5.532, 5.88, 2.0],\n [11.23, 12.88, 0.8511, 5.14, 2.795, 4.325, 5.003, 3.0],\n [19.57, 16.74, 0.8779, 6.384, 3.772, 1.472, 6.273, 2.0],\n [18.76, 16.2, 0.8984, 6.172, 3.796, 3.12, 6.053, 2.0],\n [13.22, 13.84, 0.868, 5.395, 3.07, 4.157, 5.088, 1.0],\n [12.13, 13.73, 0.8081, 5.394, 2.745, 4.825, 5.22, 3.0],\n [11.23, 12.82, 0.8594, 5.089, 2.821, 7.524, 4.957, 3.0],\n [13.78, 14.06, 0.8759, 5.479, 3.156, 3.136, 4.872, 1.0],\n [17.08, 15.38, 0.9079, 5.832, 3.683, 2.956, 5.484, 1.0],\n [13.89, 14.02, 0.888, 5.439, 3.199, 3.986, 4.738, 1.0],\n [16.44, 15.25, 0.888, 5.884, 3.505, 1.969, 5.533, 1.0],\n [10.83, 12.96, 0.8099, 5.278, 2.641, 5.182, 5.185, 3.0],\n [12.38, 13.44, 0.8609, 5.219, 2.989, 5.472, 5.045, 3.0],\n [11.18, 13.04, 0.8266, 5.22, 2.693, 3.332, 5.001, 3.0],\n [15.49, 14.94, 0.8724, 5.757, 3.371, 3.412, 5.228, 1.0],\n [14.16, 14.4, 0.8584, 5.658, 3.129, 3.072, 5.176, 1.0],\n [14.01, 14.29, 0.8625, 5.609, 3.158, 2.217, 5.132, 1.0],\n [12.55, 13.57, 0.8558, 5.333, 2.968, 4.419, 5.176, 3.0],\n [18.95, 16.42, 0.8829, 6.248, 3.755, 3.368, 6.148, 2.0],\n [13.54, 13.85, 0.8871, 5.348, 3.156, 2.587, 5.178, 1.0],\n [13.94, 14.17, 0.8728, 5.585, 3.15, 2.124, 5.012, 1.0],\n [18.14, 16.12, 0.8772, 6.059, 3.563, 3.619, 6.011, 2.0],\n [15.38, 14.9, 0.8706, 5.884, 3.268, 4.462, 5.795, 2.0],\n [15.26, 14.85, 0.8696, 5.714, 3.242, 4.543, 5.314, 1.0],\n [11.14, 12.79, 0.8558, 5.011, 2.794, 6.388, 5.049, 3.0],\n [14.7, 14.21, 0.9153, 5.205, 3.466, 1.767, 4.649, 1.0],\n [20.88, 17.05, 0.9031, 6.45, 4.032, 5.016, 6.321, 2.0],\n [17.12, 15.55, 0.8892, 5.85, 3.566, 2.858, 5.746, 2.0],\n [10.74, 12.73, 0.8329, 5.145, 2.642, 4.702, 4.963, 3.0],\n [12.26, 13.6, 0.8333, 5.408, 2.833, 4.756, 5.36, 3.0],\n [18.96, 16.2, 0.9077, 6.051, 3.897, 4.334, 5.75, 2.0],\n [14.59, 14.28, 0.8993, 5.351, 3.333, 4.185, 4.781, 1.0],\n [15.69, 14.75, 0.9058, 5.527, 3.514, 1.599, 5.046, 1.0],\n [20.03, 16.9, 0.8811, 6.493, 3.857, 3.063, 6.32, 2.0],\n [12.7, 13.71, 0.8491, 5.386, 2.911, 3.26, 5.316, 3.0],\n [17.99, 15.86, 0.8992, 5.89, 3.694, 2.068, 5.837, 2.0],\n [14.11, 14.18, 0.882, 5.541, 3.221, 2.754, 5.038, 1.0],\n [11.27, 12.86, 0.8563, 5.091, 2.804, 3.985, 5.001, 3.0],\n [11.4, 13.08, 0.8375, 5.136, 2.763, 5.588, 5.089, 3.0],\n [18.43, 15.97, 0.9077, 5.98, 3.771, 2.984, 5.905, 2.0],\n [16.14, 14.99, 0.9034, 5.658, 3.562, 1.355, 5.175, 1.0],\n [15.5, 14.86, 0.882, 5.877, 3.396, 4.711, 5.528, 1.0],\n [12.67, 13.32, 0.8977, 4.984, 3.135, 2.3, 4.745, 3.0],\n [18.89, 16.23, 0.9008, 6.227, 3.769, 3.639, 5.966, 2.0],\n [10.8, 12.57, 0.859, 4.981, 2.821, 4.773, 5.063, 3.0],\n [14.09, 14.41, 0.8529, 5.717, 3.186, 3.92, 5.299, 1.0],\n [14.03, 14.16, 0.8796, 5.438, 3.201, 1.717, 5.001, 1.0],\n [12.08, 13.23, 0.8664, 5.099, 2.936, 1.415, 4.961, 1.0],\n [15.56, 14.89, 0.8823, 5.776, 3.408, 4.972, 5.847, 2.0],\n [18.83, 16.29, 0.8917, 6.037, 3.786, 2.553, 5.879, 2.0],\n [11.84, 13.21, 0.8521, 5.175, 2.836, 3.598, 5.044, 3.0],\n [11.87, 13.02, 0.8795, 5.132, 2.953, 3.597, 5.132, 3.0],\n [13.16, 13.55, 0.9009, 5.138, 3.201, 2.461, 4.783, 1.0],\n [17.63, 15.86, 0.88, 6.033, 3.573, 3.747, 5.929, 2.0],\n [11.81, 13.45, 0.8198, 5.413, 2.716, 4.898, 5.352, 3.0],\n [11.65, 13.07, 0.8575, 5.108, 2.85, 5.209, 5.135, 3.0],\n [19.46, 16.5, 0.8985, 6.113, 3.892, 4.308, 6.009, 2.0],\n [12.79, 13.53, 0.8786, 5.224, 3.054, 5.483, 4.958, 3.0],\n [11.82, 13.4, 0.8274, 5.314, 2.777, 4.471, 5.178, 3.0],\n [13.07, 13.92, 0.848, 5.472, 2.994, 5.304, 5.395, 3.0],\n [14.49, 14.61, 0.8538, 5.715, 3.113, 4.116, 5.396, 1.0],\n [16.16, 15.33, 0.8644, 5.845, 3.395, 4.266, 5.795, 2.0],\n [12.76, 13.38, 0.8964, 5.073, 3.155, 2.828, 4.83, 3.0],\n [19.31, 16.59, 0.8815, 6.341, 3.81, 3.477, 6.238, 2.0],\n [11.43, 13.13, 0.8335, 5.176, 2.719, 2.221, 5.132, 3.0],\n [15.36, 14.76, 0.8861, 5.701, 3.393, 1.367, 5.132, 1.0],\n [11.23, 12.63, 0.884, 4.902, 2.879, 2.269, 4.703, 1.0],\n [11.55, 13.1, 0.8455, 5.167, 2.845, 6.715, 4.956, 3.0],\n [14.52, 14.6, 0.8557, 5.741, 3.113, 1.481, 5.487, 1.0],\n [12.19, 13.36, 0.8579, 5.24, 2.909, 4.857, 5.158, 3.0],\n [16.84, 15.67, 0.8623, 5.998, 3.484, 4.675, 5.877, 2.0],\n [14.34, 14.37, 0.8726, 5.63, 3.19, 1.313, 5.15, 1.0],\n [13.2, 13.66, 0.8883, 5.236, 3.232, 8.315, 5.056, 3.0],\n [16.23, 15.18, 0.885, 5.872, 3.472, 3.769, 5.922, 2.0],\n [14.86, 14.67, 0.8676, 5.678, 3.258, 2.129, 5.351, 1.0],\n [10.59, 12.41, 0.8648, 4.899, 2.787, 4.975, 4.794, 3.0],\n [12.15, 13.45, 0.8443, 5.417, 2.837, 3.638, 5.338, 3.0],\n [12.49, 13.46, 0.8658, 5.267, 2.967, 4.421, 5.002, 3.0],\n [11.26, 13.01, 0.8355, 5.186, 2.71, 5.335, 5.092, 3.0],\n [19.51, 16.71, 0.878, 6.366, 3.801, 2.962, 6.185, 2.0],\n [12.3, 13.34, 0.8684, 5.243, 2.974, 5.637, 5.063, 3.0],\n [11.56, 13.31, 0.8198, 5.363, 2.683, 4.062, 5.182, 3.0],\n [13.8, 14.04, 0.8794, 5.376, 3.155, 1.56, 4.961, 1.0],\n [19.11, 16.26, 0.9081, 6.154, 3.93, 2.936, 6.079, 2.0],\n [15.57, 15.15, 0.8527, 5.92, 3.231, 2.64, 5.879, 2.0],\n [12.37, 13.47, 0.8567, 5.204, 2.96, 3.919, 5.001, 3.0],\n [15.78, 14.91, 0.8923, 5.674, 3.434, 5.593, 5.136, 1.0],\n [19.38, 16.72, 0.8716, 6.303, 3.791, 3.678, 5.965, 2.0],\n [17.63, 15.98, 0.8673, 6.191, 3.561, 4.076, 6.06, 2.0],\n [12.73, 13.75, 0.8458, 5.412, 2.882, 3.533, 5.067, 1.0],\n [11.34, 12.87, 0.8596, 5.053, 2.849, 3.347, 5.003, 3.0],\n [18.17, 16.26, 0.8637, 6.271, 3.512, 2.853, 6.273, 2.0],\n [14.88, 14.57, 0.8811, 5.554, 3.333, 1.018, 4.956, 1.0],\n [13.45, 14.02, 0.8604, 5.516, 3.065, 3.531, 5.097, 1.0],\n [12.78, 13.57, 0.8716, 5.262, 3.026, 1.176, 4.782, 1.0],\n [10.91, 12.8, 0.8372, 5.088, 2.675, 4.179, 4.956, 3.0],\n [14.11, 14.26, 0.8722, 5.52, 3.168, 2.688, 5.219, 1.0],\n [20.2, 16.89, 0.8894, 6.285, 3.864, 5.173, 6.187, 2.0],\n [14.43, 14.4, 0.8751, 5.585, 3.272, 3.975, 5.144, 1.0],\n [12.54, 13.67, 0.8425, 5.451, 2.879, 3.082, 5.491, 3.0],\n [11.36, 13.05, 0.8382, 5.175, 2.755, 4.048, 5.263, 3.0],\n [18.94, 16.49, 0.875, 6.445, 3.639, 5.064, 6.362, 2.0],\n [11.83, 13.23, 0.8496, 5.263, 2.84, 5.195, 5.307, 3.0],\n [20.1, 16.99, 0.8746, 6.581, 3.785, 1.955, 6.449, 2.0],\n [14.28, 14.17, 0.8944, 5.397, 3.298, 6.685, 5.001, 1.0],\n [11.49, 13.22, 0.8263, 5.304, 2.695, 5.388, 5.31, 3.0],\n [11.42, 12.86, 0.8683, 5.008, 2.85, 2.7, 4.607, 1.0],\n [13.84, 13.94, 0.8955, 5.324, 3.379, 2.259, 4.805, 1.0],\n [17.36, 15.76, 0.8785, 6.145, 3.574, 3.526, 5.971, 2.0],\n [18.75, 16.18, 0.8999, 6.111, 3.869, 4.188, 5.992, 2.0],\n [18.36, 16.52, 0.8452, 6.666, 3.485, 4.933, 6.448, 2.0],\n [12.22, 13.32, 0.8652, 5.224, 2.967, 5.469, 5.221, 3.0],\n [13.5, 13.85, 0.8852, 5.351, 3.158, 2.249, 5.176, 1.0],\n [12.74, 13.67, 0.8564, 5.395, 2.956, 2.504, 4.869, 1.0],\n [18.3, 15.89, 0.9108, 5.979, 3.755, 2.837, 5.962, 2.0],\n [11.35, 13.12, 0.8291, 5.176, 2.668, 4.337, 5.132, 3.0],\n [15.88, 14.9, 0.8988, 5.618, 3.507, 0.7651, 5.091, 1.0],\n [16.87, 15.65, 0.8648, 6.139, 3.463, 3.696, 5.967, 2.0],\n [18.59, 16.05, 0.9066, 6.037, 3.86, 6.001, 5.877, 2.0],\n [15.11, 14.54, 0.8986, 5.579, 3.462, 3.128, 5.18, 1.0],\n [11.75, 13.52, 0.8082, 5.444, 2.678, 4.378, 5.31, 3.0],\n [19.18, 16.63, 0.8717, 6.369, 3.681, 3.357, 6.229, 2.0],\n [12.36, 13.19, 0.8923, 5.076, 3.042, 3.22, 4.605, 1.0],\n [16.17, 15.38, 0.8588, 5.762, 3.387, 4.286, 5.703, 2.0],\n [16.63, 15.46, 0.8747, 6.053, 3.465, 2.04, 5.877, 1.0],\n [16.41, 15.25, 0.8866, 5.718, 3.525, 4.217, 5.618, 2.0],\n [10.79, 12.93, 0.8107, 5.317, 2.648, 5.462, 5.194, 3.0],\n [17.98, 15.85, 0.8993, 5.979, 3.687, 2.257, 5.919, 2.0],\n [17.26, 15.73, 0.8763, 5.978, 3.594, 4.539, 5.791, 2.0],\n [20.71, 17.23, 0.8763, 6.579, 3.814, 4.451, 6.451, 2.0],\n [14.79, 14.52, 0.8819, 5.545, 3.291, 2.704, 5.111, 1.0],\n [17.55, 15.66, 0.8991, 5.791, 3.69, 5.366, 5.661, 2.0],\n [11.27, 12.97, 0.8419, 5.088, 2.763, 4.309, 5.0, 3.0],\n [20.16, 17.03, 0.8735, 6.513, 3.773, 1.91, 6.185, 2.0],\n [18.27, 16.09, 0.887, 6.173, 3.651, 2.443, 6.197, 2.0],\n [12.7, 13.41, 0.8874, 5.183, 3.091, 8.456, 5.0, 3.0],\n [16.77, 15.62, 0.8638, 5.927, 3.438, 4.92, 5.795, 2.0],\n [14.99, 14.56, 0.8883, 5.57, 3.377, 2.958, 5.175, 1.0],\n [16.19, 15.16, 0.8849, 5.833, 3.421, 0.903, 5.307, 1.0],\n [13.34, 13.95, 0.862, 5.389, 3.074, 5.995, 5.307, 3.0],\n [18.85, 16.17, 0.9056, 6.152, 3.806, 2.843, 6.2, 2.0],\n [12.21, 13.47, 0.8453, 5.357, 2.893, 1.661, 5.178, 3.0],\n [16.82, 15.51, 0.8786, 6.017, 3.486, 4.004, 5.841, 2.0],\n [19.15, 16.45, 0.889, 6.245, 3.815, 3.084, 6.185, 2.0],\n [11.24, 13.0, 0.8359, 5.09, 2.715, 3.521, 5.088, 3.0],\n [12.1, 13.15, 0.8793, 5.105, 2.941, 2.201, 5.056, 3.0],\n [21.18, 17.21, 0.8989, 6.573, 4.033, 5.78, 6.231, 2.0],\n [12.11, 13.47, 0.8392, 5.159, 3.032, 1.502, 4.519, 1.0],\n [13.32, 13.94, 0.8613, 5.541, 3.073, 7.035, 5.44, 3.0],\n [11.18, 12.72, 0.868, 5.009, 2.81, 4.051, 4.828, 3.0],\n [19.13, 16.31, 0.9035, 6.183, 3.902, 2.109, 5.924, 2.0],\n [14.46, 14.35, 0.8818, 5.388, 3.377, 2.802, 5.044, 1.0],\n [15.38, 14.66, 0.899, 5.477, 3.465, 3.6, 5.439, 2.0],\n [11.41, 12.95, 0.856, 5.09, 2.775, 4.957, 4.825, 3.0],\n [19.94, 16.92, 0.8752, 6.675, 3.763, 3.252, 6.55, 2.0],\n [15.03, 14.77, 0.8658, 5.702, 3.212, 1.933, 5.439, 1.0],\n [13.37, 13.78, 0.8849, 5.32, 3.128, 4.67, 5.091, 3.0],\n [14.29, 14.09, 0.905, 5.291, 3.337, 2.699, 4.825, 1.0],\n [15.6, 15.11, 0.858, 5.832, 3.286, 2.725, 5.752, 2.0],\n [12.62, 13.67, 0.8481, 5.41, 2.911, 3.306, 5.231, 3.0],\n [14.69, 14.49, 0.8799, 5.563, 3.259, 3.586, 5.219, 1.0],\n [14.38, 14.21, 0.8951, 5.386, 3.312, 2.462, 4.956, 1.0],\n [10.82, 12.83, 0.8256, 5.18, 2.63, 4.853, 5.089, 3.0],\n [18.72, 16.19, 0.8977, 6.006, 3.857, 5.324, 5.879, 2.0],\n [13.02, 13.76, 0.8641, 5.395, 3.026, 3.373, 4.825, 1.0],\n [12.01, 13.52, 0.8249, 5.405, 2.776, 6.992, 5.27, 3.0],\n [15.38, 14.77, 0.8857, 5.662, 3.419, 1.999, 5.222, 1.0],\n [12.89, 13.77, 0.8541, 5.495, 3.026, 6.185, 5.316, 3.0],\n [14.37, 14.39, 0.8726, 5.569, 3.153, 1.464, 5.3, 1.0],\n [20.97, 17.25, 0.8859, 6.563, 3.991, 4.677, 6.316, 2.0],\n [11.48, 13.05, 0.8473, 5.18, 2.758, 5.876, 5.002, 3.0],\n [15.26, 14.84, 0.871, 5.763, 3.312, 2.221, 5.22, 1.0],\n [11.19, 13.05, 0.8253, 5.25, 2.675, 5.813, 5.219, 3.0],\n [18.45, 16.12, 0.8921, 6.107, 3.769, 2.235, 5.794, 2.0],\n [18.72, 16.34, 0.881, 6.219, 3.684, 2.188, 6.097, 2.0],\n [14.11, 14.1, 0.8911, 5.42, 3.302, 2.7, 5.0, 1.0],\n [15.99, 14.89, 0.9064, 5.363, 3.582, 3.336, 5.144, 2.0],\n [15.01, 14.76, 0.8657, 5.789, 3.245, 1.791, 5.001, 1.0],\n [14.33, 14.28, 0.8831, 5.504, 3.199, 3.328, 5.224, 1.0],\n [18.98, 16.57, 0.8687, 6.449, 3.552, 2.144, 6.453, 2.0],\n [12.44, 13.59, 0.8462, 5.319, 2.897, 4.924, 5.27, 3.0],\n [20.24, 16.91, 0.8897, 6.315, 3.962, 5.901, 6.188, 2.0],\n [19.06, 16.45, 0.8854, 6.416, 3.719, 2.248, 6.163, 2.0],\n [12.11, 13.27, 0.8639, 5.236, 2.975, 4.132, 5.012, 3.0],\n [18.65, 16.41, 0.8698, 6.285, 3.594, 4.391, 6.102, 2.0],\n [13.16, 13.82, 0.8662, 5.454, 2.975, 0.8551, 5.056, 1.0],\n [12.88, 13.5, 0.8879, 5.139, 3.119, 2.352, 4.607, 1.0],\n [13.99, 13.83, 0.9183, 5.119, 3.383, 5.234, 4.781, 1.0],\n [12.8, 13.47, 0.886, 5.16, 3.126, 4.873, 4.914, 3.0],\n [12.19, 13.2, 0.8783, 5.137, 2.981, 3.631, 4.87, 3.0],\n [11.21, 13.13, 0.8167, 5.279, 2.687, 6.169, 5.275, 3.0],\n [15.05, 14.68, 0.8779, 5.712, 3.328, 2.129, 5.36, 1.0]]"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00048-05cc4663-ae97-471f-ba8b-6b9bd07ad198","deepnote_to_be_reexecuted":false,"source_hash":"e93f81d3","execution_millis":5,"execution_start":1612396856215,"deepnote_cell_type":"code"},"source":"def minmax(dataset): \n    max_per_col, min_per_col, diff = [], [], []\n    for i in range(len(dataset[0])):\n        column = [] \n        for j in range(len(dataset)): \n            column.append(dataset[j][i])\n        max_per_col.append(max(column))\n        min_per_col.append(min(column))\n        diff.append(max(column) - min(column))\n    return (min_per_col, max_per_col, diff)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00047-edbcee62-24ea-44cb-9dde-e43b2418f291","deepnote_to_be_reexecuted":false,"source_hash":"70c264cc","execution_millis":0,"execution_start":1612396856258,"deepnote_cell_type":"code"},"source":"def minmax_normalization(dataset): \n    normalized_dataset = []\n    mini, maxi, diff = minmax(dataset)\n    for i in range(len(dataset)): \n        value = []\n        for j in range(len(dataset[0]) - 1): \n            # normalized_value = value - min / max - min\n            value.append((dataset[i][j] - mini[j]) / diff[j])\n        value.append(int(dataset[i][len(dataset[0])-1]) -1)\n        normalized_dataset.append(value)\n    return normalized_dataset","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00045-6be9b460-84f0-4287-bb9e-ac3de1a7e07c","deepnote_to_be_reexecuted":false,"source_hash":"80344da9","execution_millis":7,"execution_start":1612396856258,"deepnote_cell_type":"code"},"source":"normalized_dataset = minmax_normalization(dataset)\nnormalized_dataset","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"[[0.408876298394712,\n  0.4173553719008264,\n  0.8393829401088925,\n  0.2730855855855858,\n  0.5573770491803277,\n  0.04900596809216086,\n  0.2801575578532743,\n  0],\n [0.7922568460812087,\n  0.878099173553719,\n  0.4618874773139742,\n  0.9290540540540544,\n  0.7412687099073412,\n  0.380436619901442,\n  0.9743968488429348,\n  1],\n [0.7884796978281399,\n  0.8078512396694215,\n  0.7813067150635207,\n  0.7010135135135136,\n  0.8517462580185317,\n  0.27862798892197277,\n  0.7040866568193008,\n  1],\n [0.13503305004721433,\n  0.19008264462809915,\n  0.38294010889292124,\n  0.25394144144144126,\n  0.128296507483963,\n  0.4558504206269748,\n  0.38847858197932045,\n  2],\n [0.7828139754485363,\n  0.7954545454545457,\n  0.8058076225045374,\n  0.6672297297297296,\n  0.8082679971489661,\n  0.11492803182982488,\n  0.7828655834564254,\n  1],\n [0.13786591123701614,\n  0.2066115702479339,\n  0.3039927404718692,\n  0.20720720720720742,\n  0.15466856735566645,\n  0.5490774811790559,\n  0.25947808961102914,\n  2],\n [0.1765816808309727,\n  0.2066115702479339,\n  0.5671506352087116,\n  0.18975225225225212,\n  0.27583749109052025,\n  0.5489474573847014,\n  0.30920728705071404,\n  2],\n [0.2974504249291785,\n  0.3388429752066117,\n  0.6016333938294005,\n  0.3282657657657659,\n  0.344975053456878,\n  0.2817485599864776,\n  0.15066469719350079,\n  0],\n [0.8073654390934845,\n  0.8677685950413222,\n  0.5816696914700541,\n  0.765765765765766,\n  0.789023521026372,\n  0.7693377888153533,\n  0.7552929591334319,\n  1],\n [0.3975448536355053,\n  0.4359504132231404,\n  0.6733212341197818,\n  0.4262387387387386,\n  0.4689950106913754,\n  0.3051528429702636,\n  0.38897095027080264,\n  0],\n [0.5221907459867801,\n  0.5351239669421487,\n  0.8339382940108894,\n  0.4560810810810809,\n  0.6094084105488238,\n  0.1956728081238867,\n  0.4549483013293942,\n  0],\n [0.635505193578848,\n  0.7231404958677686,\n  0.4700544464609798,\n  0.6559684684684686,\n  0.5509622238061296,\n  0.3977297845505728,\n  0.690792712949286,\n  1],\n [0.7762039660056657,\n  0.8016528925619832,\n  0.7486388384754985,\n  0.7730855855855858,\n  0.7576621525302921,\n  0.32140581726455947,\n  0.7552929591334319,\n  1],\n [0.040604343720491,\n  0.12190082644628096,\n  0.09800362976406465,\n  0.23986486486486497,\n  0.05060584461867438,\n  0.7762290499161347,\n  0.3170851797144265,\n  2],\n [0.20113314447592076,\n  0.23966942148760334,\n  0.5490018148820328,\n  0.18412162162162163,\n  0.2986457590876692,\n  0.43387639938108685,\n  0.1944854751354011,\n  0],\n [0.5297450424929178,\n  0.5909090909090908,\n  0.5925589836660611,\n  0.5219594594594593,\n  0.5944404846756948,\n  0.26757596640185155,\n  0.49630723781388486,\n  0],\n [0.03210576015108592,\n  0.08057851239669434,\n  0.28039927404718634,\n  0.08277027027027041,\n  0.06200997861724886,\n  0.6023872368643461,\n  0.25898572131954695,\n  2],\n [0.7516525023607178,\n  0.7871900826446279,\n  0.7114337568058071,\n  0.7060810810810809,\n  0.7441197434069848,\n  0.12650014952736352,\n  0.6770064007877894,\n  1],\n [0.5609065155807367,\n  0.6053719008264462,\n  0.6733212341197818,\n  0.5495495495495496,\n  0.5965787598004276,\n  0.6198104253078314,\n  0.6701132447070408,\n  1],\n [0.06043437204910298,\n  0.09710743801652906,\n  0.39019963702359295,\n  0.13569819819819803,\n  0.11760513186029935,\n  0.46287170552211065,\n  0.23830625307730186,\n  2],\n [0.8479697828139755,\n  0.8946280991735533,\n  0.6333938294010889,\n  0.8361486486486489,\n  0.8139700641482533,\n  0.09191382022910193,\n  0.863613983259478,\n  1],\n [0.7714825306893297,\n  0.7830578512396693,\n  0.819419237749546,\n  0.7167792792792792,\n  0.8310762651461151,\n  0.30619303332509856,\n  0.7552929591334319,\n  1],\n [0.2483474976392824,\n  0.2954545454545454,\n  0.5435571687840288,\n  0.27927927927927904,\n  0.31361368496079817,\n  0.441027708070577,\n  0.2801575578532743,\n  0],\n [0.145420207743154,\n  0.2727272727272728,\n  0.0,\n  0.2787162162162163,\n  0.08196721311475422,\n  0.527883602699294,\n  0.3451501723289019,\n  2],\n [0.06043437204910298,\n  0.08471074380165293,\n  0.4655172413793106,\n  0.10698198198198221,\n  0.13613684960798306,\n  0.8788178236617301,\n  0.2156573116691284,\n  2],\n [0.30122757318224735,\n  0.340909090909091,\n  0.6152450090744102,\n  0.3265765765765766,\n  0.3749109052031362,\n  0.30827341403476843,\n  0.17380600689315598,\n  0],\n [0.6128423040604343,\n  0.6136363636363638,\n  0.9056261343012707,\n  0.5253378378378378,\n  0.7505345687811829,\n  0.2848691310509824,\n  0.4751354012801576,\n  0],\n [0.31161473087818703,\n  0.33264462809917344,\n  0.7250453720508166,\n  0.3040540540540541,\n  0.4055595153243049,\n  0.4187936392359803,\n  0.10782865583456443,\n  0],\n [0.5524079320113315,\n  0.5867768595041322,\n  0.7250453720508166,\n  0.5546171171171174,\n  0.6236635780470419,\n  0.15653564602322226,\n  0.4992614475627771,\n  0],\n [0.02266288951841362,\n  0.11363636363636379,\n  0.016333938294010104,\n  0.21340090090090066,\n  0.007840342124020041,\n  0.574302097283803,\n  0.3279172821270308,\n  2],\n [0.16902738432483483,\n  0.21280991735537177,\n  0.4791288566243192,\n  0.18018018018018037,\n  0.2558802565930149,\n  0.6120089976465694,\n  0.25898572131954695,\n  2],\n [0.05571293673276675,\n  0.13016528925619814,\n  0.1678765880217783,\n  0.18074324324324312,\n  0.04490377761938713,\n  0.3337580777282243,\n  0.23732151649433791,\n  2],\n [0.4627006610009443,\n  0.5227272727272726,\n  0.5834845735027218,\n  0.48310810810810795,\n  0.5281539558089806,\n  0.34415998127657366,\n  0.3490891186607581,\n  0],\n [0.3371104815864023,\n  0.4111570247933885,\n  0.45644283121597123,\n  0.4273648648648651,\n  0.35566642908054164,\n  0.29995189119608895,\n  0.32348596750369285,\n  0],\n [0.32294617563739375,\n  0.3884297520661155,\n  0.4936479128856626,\n  0.3997747747747748,\n  0.37633642195295786,\n  0.18878154702310526,\n  0.3018217626784833,\n  0],\n [0.1850802644003778,\n  0.23966942148760334,\n  0.4328493647912884,\n  0.24436936936936948,\n  0.24091233071988594,\n  0.47509394219142104,\n  0.32348596750369285,\n  2],\n [0.789423984891407,\n  0.8285123966942152,\n  0.6787658802177858,\n  0.7595720720720722,\n  0.8018531717747681,\n  0.3384389343249815,\n  0.8020679468242244,\n  1],\n [0.27856468366383375,\n  0.2975206611570247,\n  0.7168784029038111,\n  0.25281531531531526,\n  0.3749109052031362,\n  0.23689035093422103,\n  0.3244707040866568,\n  0],\n [0.3163361661945231,\n  0.3636363636363636,\n  0.5871143375680581,\n  0.38626126126126126,\n  0.3706343549536706,\n  0.17668933414814916,\n  0.24273756770063984,\n  0],\n [0.7129367327667612,\n  0.7665289256198349,\n  0.627041742286751,\n  0.6531531531531533,\n  0.6650035637918745,\n  0.37107490670792764,\n  0.7346134908911867,\n  1],\n [0.4523135033050048,\n  0.5144628099173554,\n  0.5671506352087116,\n  0.5546171171171174,\n  0.4547398431931573,\n  0.48068496534865884,\n  0.6282619399310684,\n  1],\n [0.4409820585457979,\n  0.5041322314049586,\n  0.5580762250453722,\n  0.4588963963963967,\n  0.4362081254454739,\n  0.4912168926913626,\n  0.3914327917282127,\n  0],\n [0.051935788479697896,\n  0.07851239669421467,\n  0.4328493647912884,\n  0.06306306306306313,\n  0.11689237348538851,\n  0.7311107932751694,\n  0.2609551944854753,\n  2],\n [0.38810198300283283,\n  0.37190082644628114,\n  0.9727767695099818,\n  0.17229729729729734,\n  0.5958660014255167,\n  0.13027083956364016,\n  0.06400787789266367,\n  0],\n [0.971671388101983,\n  0.9586776859504134,\n  0.8620689655172414,\n  0.873310810810811,\n  0.9992872416250889,\n  0.552718147420978,\n  0.8872476612506154,\n  1],\n [0.6166194523135035,\n  0.6487603305785126,\n  0.7359346642468237,\n  0.5354729729729728,\n  0.667141838916607,\n  0.2721267992042544,\n  0.6041358936484493,\n  1],\n [0.014164305949008532,\n  0.0661157024793389,\n  0.22504537205081615,\n  0.13851351351351326,\n  0.008553100498930866,\n  0.5118906759937069,\n  0.21861152141802068,\n  2],\n [0.15769593956562794,\n  0.24586776859504123,\n  0.22867513611615253,\n  0.2865990990990993,\n  0.1446899501069139,\n  0.5189119608888427,\n  0.4140817331363862,\n  2],\n [0.7903682719546743,\n  0.7830578512396693,\n  0.903811252268602,\n  0.6486486486486488,\n  0.9030648610121165,\n  0.4640419196712999,\n  0.6061053668143772,\n  1],\n [0.3777148253068933,\n  0.3863636363636362,\n  0.8275862068965515,\n  0.2545045045045045,\n  0.5010691375623664,\n  0.44466837431249917,\n  0.12900049236829128,\n  0],\n [0.4815864022662889,\n  0.4834710743801653,\n  0.8865698729582581,\n  0.3536036036036037,\n  0.6300784034212399,\n  0.10842684211210653,\n  0.25947808961102914,\n  0],\n [0.8914069877242683,\n  0.9276859504132229,\n  0.6624319419237747,\n  0.8975225225225228,\n  0.8745545260156806,\n  0.2987816770468997,\n  0.8867552929591337,\n  1],\n [0.19924457034938617,\n  0.2685950413223142,\n  0.37205081669691414,\n  0.2742117117117118,\n  0.20028510334996438,\n  0.3243963645347099,\n  0.39241752831117666,\n  2],\n [0.6987724268177524,\n  0.7128099173553718,\n  0.8266787658802177,\n  0.5579954954954953,\n  0.7583749109052029,\n  0.1694080016643046,\n  0.6489414081733136,\n  1],\n [0.33238904627006605,\n  0.3657024793388429,\n  0.6705989110707803,\n  0.36148648648648674,\n  0.421240199572345,\n  0.25860432459140026,\n  0.25553914327917293,\n  0],\n [0.06421152030217184,\n  0.0929752066115701,\n  0.4373865698729576,\n  0.10810810810810821,\n  0.12401995723449742,\n  0.41866361544162584,\n  0.23732151649433791,\n  2],\n [0.07648725212464594,\n  0.13842975206611569,\n  0.26678765880217775,\n  0.13344594594594603,\n  0.09479686386315037,\n  0.6270917577916759,\n  0.2806499261447565,\n  2],\n [0.7403210576015109,\n  0.7355371900826447,\n  0.903811252268602,\n  0.6086711711711714,\n  0.8132573057733425,\n  0.28850979729290466,\n  0.6824224519940918,\n  1],\n [0.5240793201133145,\n  0.5330578512396694,\n  0.8647912885662429,\n  0.4273648648648651,\n  0.6642908054169634,\n  0.076701036289641,\n  0.32299359921221066,\n  0],\n [0.4636449480642115,\n  0.5061983471074378,\n  0.6705989110707803,\n  0.5506756756756755,\n  0.5459729151817532,\n  0.5130608901428962,\n  0.4967996061053666,\n  0],\n [0.19641170915958453,\n  0.18801652892561987,\n  0.8130671506352091,\n  0.04786036036036034,\n  0.3599429793300069,\n  0.1995735219545177,\n  0.11127523387493846,\n  2],\n [0.7837582625118037,\n  0.7892561983471075,\n  0.8411978221415611,\n  0.747747747747748,\n  0.8118317890235209,\n  0.3736753825950149,\n  0.7124569177744955,\n  1],\n [0.019830028328611977,\n  0.03305785123966945,\n  0.4618874773139742,\n  0.046171171171171095,\n  0.13613684960798306,\n  0.5211223653928668,\n  0.26784835056622336,\n  2],\n [0.3305004721435316,\n  0.4132231404958678,\n  0.40653357531760403,\n  0.46058558558558543,\n  0.3962936564504632,\n  0.410212068808592,\n  0.38404726735598244,\n  0],\n [0.3248347497639282,\n  0.3615702479338843,\n  0.6488203266787662,\n  0.30349099099099086,\n  0.40698503207412684,\n  0.12376964984592183,\n  0.23732151649433791,\n  0],\n [0.14069877242681778,\n  0.16942148760330586,\n  0.5290381125226854,\n  0.11261261261261273,\n  0.21810406272273694,\n  0.08450246395090302,\n  0.21762678483505674,\n  0],\n [0.46931067044381497,\n  0.5123966942148761,\n  0.6733212341197818,\n  0.49380630630630623,\n  0.554526015680684,\n  0.546997100469386,\n  0.6538650910881342,\n  1],\n [0.7780925401322001,\n  0.8016528925619832,\n  0.7586206896551727,\n  0.6407657657657658,\n  0.8239486813970063,\n  0.23246954192617253,\n  0.6696208764155587,\n  1],\n [0.11803588290840415,\n  0.16528925619834725,\n  0.3992740471869323,\n  0.15540540540540532,\n  0.1468282252316464,\n  0.3683444070264859,\n  0.25849335302806475,\n  2],\n [0.12086874409820579,\n  0.12603305785123955,\n  0.6479128856624313,\n  0.13119369369369352,\n  0.23022095509622226,\n  0.3682143832321315,\n  0.3018217626784833,\n  2],\n [0.24268177525967896,\n  0.23553719008264476,\n  0.8421052631578949,\n  0.13457207207207203,\n  0.40698503207412684,\n  0.22050735284557077,\n  0.12998522895125567,\n  0],\n [0.6647780925401321,\n  0.7128099173553718,\n  0.6524500907441015,\n  0.6385135135135138,\n  0.6721311475409835,\n  0.38771795238528656,\n  0.6942392909896604,\n  1],\n [0.11520302171860251,\n  0.21487603305785108,\n  0.10617059891107021,\n  0.28941441441441457,\n  0.06129722024233804,\n  0.5373753396871628,\n  0.4101427868045299,\n  2],\n [0.10009442870632677,\n  0.1363636363636364,\n  0.44827586206896564,\n  0.11768018018017999,\n  0.15680684248039922,\n  0.5778127397313708,\n  0.30329886755292945,\n  2],\n [0.8375826251180359,\n  0.8450413223140496,\n  0.8203266787658798,\n  0.6835585585585588,\n  0.8995010691375621,\n  0.46066130101808633,\n  0.7336287543082227,\n  1],\n [0.20774315391879125,\n  0.2314049586776858,\n  0.6397459165154268,\n  0.18299549549549562,\n  0.3022095509622237,\n  0.6134392593844673,\n  0.2161496799606106,\n  2],\n [0.11614730878186973,\n  0.20454545454545459,\n  0.17513611615245,\n  0.23367117117117123,\n  0.1047754811119032,\n  0.4818551794978482,\n  0.3244707040866568,\n  2],\n [0.23418319169027388,\n  0.3119834710743801,\n  0.36206896551724094,\n  0.3226351351351354,\n  0.25944404846756963,\n  0.5901650001950357,\n  0.4313146233382568,\n  2],\n [0.368271954674221,\n  0.4545454545454544,\n  0.4147005444646096,\n  0.45945945945945943,\n  0.34426229508196715,\n  0.4356967325020479,\n  0.431806991629739,\n  0],\n [0.5259678942398489,\n  0.6033057851239669,\n  0.5108892921960065,\n  0.5326576576576576,\n  0.5452601568068424,\n  0.455200301655203,\n  0.6282619399310684,\n  1],\n [0.2049102927289896,\n  0.200413223140496,\n  0.8012704174228672,\n  0.0979729729729732,\n  0.37419814682822505,\n  0.2682260853736234,\n  0.1531265386509109,\n  2],\n [0.8234183191690273,\n  0.8636363636363636,\n  0.6660617059891101,\n  0.8119369369369371,\n  0.8410548823948679,\n  0.3526115279096075,\n  0.8463810930576073,\n  1],\n [0.07932011331444758,\n  0.14876033057851254,\n  0.2304900181488202,\n  0.15596846846846857,\n  0.06343549536707052,\n  0.18930164220052273,\n  0.3018217626784833,\n  2],\n [0.4504249291784702,\n  0.48553719008264457,\n  0.7078039927404717,\n  0.4515765765765764,\n  0.5438346400570204,\n  0.07826132182189341,\n  0.3018217626784833,\n  0],\n [0.06043437204910298,\n  0.04545454545454559,\n  0.688747731397459,\n  0.0016891891891892535,\n  0.17747683535281542,\n  0.19554278432953234,\n  0.09059576563269335,\n  0],\n [0.09065155807365448,\n  0.1425619834710743,\n  0.3393829401088929,\n  0.1509009009009008,\n  0.15324305060584478,\n  0.7736285740290474,\n  0.21516494337764666,\n  2],\n [0.37110481586402266,\n  0.45247933884297514,\n  0.43194192377495455,\n  0.474099099099099,\n  0.34426229508196715,\n  0.09308403437829126,\n  0.4766125061546037,\n  0],\n [0.15108593012275728,\n  0.19628099173553704,\n  0.451905626134301,\n  0.19200450450450463,\n  0.1988595866001424,\n  0.5320443641186338,\n  0.31462333825701644,\n  2],\n [0.5901794145420208,\n  0.6735537190082644,\n  0.49183303085299396,\n  0.6188063063063065,\n  0.6086956521739129,\n  0.508380033546139,\n  0.6686361398325947,\n  1],\n [0.35410764872521244,\n  0.40495867768595023,\n  0.5852994555353904,\n  0.4115990990990991,\n  0.3991446899501068,\n  0.0712400369267576,\n  0.3106843919251602,\n  0],\n [0.2464589235127478,\n  0.2582644628099174,\n  0.7277676950998182,\n  0.18975225225225212,\n  0.429080541696365,\n  0.9816666449960343,\n  0.26440177252584934,\n  2],\n [0.5325779036827196,\n  0.5723140495867768,\n  0.6978221415607985,\n  0.5478603603603603,\n  0.600142551674982,\n  0.39057847586108263,\n  0.690792712949286,\n  1],\n [0.40321057601510857,\n  0.4669421487603305,\n  0.5399274047186934,\n  0.4386261261261261,\n  0.4476122594440484,\n  0.17733945311992097,\n  0.40965041851304773,\n  0],\n [0.0,\n  0.0,\n  0.514519056261343,\n  0.0,\n  0.1119030648610121,\n  0.547387171852449,\n  0.13540128015755762,\n  2],\n [0.14730878186968843,\n  0.21487603305785108,\n  0.3284936479128859,\n  0.2916666666666666,\n  0.14754098360655754,\n  0.3735453588006606,\n  0.40324963072378145,\n  2],\n [0.17941454202077436,\n  0.21694214876033074,\n  0.5235934664246823,\n  0.20720720720720742,\n  0.2401995723449751,\n  0.4753539897801299,\n  0.23781388478581966,\n  2],\n [0.06326723323890462,\n  0.12396694214876026,\n  0.248638838475499,\n  0.16159909909909909,\n  0.05702066999287245,\n  0.5941957378200211,\n  0.28212703101920217,\n  2],\n [0.8423040604343722,\n  0.8884297520661159,\n  0.6343012704174227,\n  0.8260135135135134,\n  0.8346400570206699,\n  0.2856492738171086,\n  0.8202855736090594,\n  1],\n [0.16147308781869696,\n  0.19214876033057846,\n  0.5471869328493641,\n  0.19369369369369388,\n  0.2451888809693515,\n  0.6334629237150399,\n  0.26784835056622336,\n  2],\n [0.09159584513692169,\n  0.18595041322314057,\n  0.10617059891107021,\n  0.26126126126126153,\n  0.03777619387027792,\n  0.4286754476069122,\n  0.3264401772525851,\n  2],\n [0.30311614730878195,\n  0.33677685950413205,\n  0.6470054446460974,\n  0.2685810810810813,\n  0.37419814682822505,\n  0.10335591413228623,\n  0.21762678483505674,\n  0],\n [0.8045325779036827,\n  0.7954545454545457,\n  0.9074410163339384,\n  0.7066441441441441,\n  0.9265858873841767,\n  0.28226865516389504,\n  0.7680945347119644,\n  1],\n [0.4702549575070822,\n  0.566115702479339,\n  0.40471869328493637,\n  0.5748873873873874,\n  0.42836778332145387,\n  0.24378161203500245,\n  0.6696208764155587,\n  1],\n [0.16808309726156745,\n  0.21900826446281002,\n  0.4410163339382939,\n  0.1717342342342341,\n  0.2352102637205987,\n  0.4100820450142377,\n  0.23732151649433791,\n  2],\n [0.490084985835694,\n  0.5165289256198348,\n  0.7640653357531758,\n  0.4363738738738741,\n  0.5730577334283677,\n  0.6277418767634477,\n  0.30379123584441164,\n  0],\n [0.8300283286118979,\n  0.8904958677685948,\n  0.576225045372051,\n  0.7905405405405406,\n  0.8275124732715606,\n  0.37874631057483527,\n  0.7119645494830132,\n  1],\n [0.6647780925401321,\n  0.737603305785124,\n  0.5372050816696909,\n  0.7274774774774775,\n  0.6635780470420526,\n  0.4304957807278732,\n  0.7587395371738058,\n  1],\n [0.20207743153918797,\n  0.27685950413223137,\n  0.34210526315789447,\n  0.2888513513513513,\n  0.17961511047754822,\n  0.35989286039345203,\n  0.2698178237321517,\n  0],\n [0.0708215297450425,\n  0.0950413223140494,\n  0.4673321234119783,\n  0.08671171171171167,\n  0.15609408410548842,\n  0.33570843464353983,\n  0.23830625307730186,\n  2],\n [0.715769593956563,\n  0.7954545454545457,\n  0.5045372050816697,\n  0.7725225225225225,\n  0.6286528866714183,\n  0.2714766802324826,\n  0.863613983259478,\n  1],\n [0.40509915014164316,\n  0.44628099173553726,\n  0.6624319419237747,\n  0.3688063063063065,\n  0.5010691375623664,\n  0.03288301759221938,\n  0.21516494337764666,\n  0],\n [0.27006610009442866,\n  0.33264462809917344,\n  0.47459165154265,\n  0.34740990990990994,\n  0.3100498930862437,\n  0.35963281280474335,\n  0.2845888724766127,\n  0],\n [0.20679886685552404,\n  0.23966942148760334,\n  0.576225045372051,\n  0.20439189189189166,\n  0.2822523164647183,\n  0.053426777100209336,\n  0.12949286065977347,\n  0],\n [0.03021718602455149,\n  0.08057851239669434,\n  0.26406533575317626,\n  0.10641891891891896,\n  0.03207412687099067,\n  0.4438882315463731,\n  0.21516494337764666,\n  2],\n [0.33238904627006605,\n  0.38223140495867763,\n  0.5816696914700541,\n  0.34966216216216195,\n  0.38346400570206707,\n  0.2500227541640121,\n  0.34465780403742013,\n  0],\n [0.9074598677998111,\n  0.9256198347107439,\n  0.7377495462794914,\n  0.7804054054054056,\n  0.8795438346400567,\n  0.5731318831346136,\n  0.8212703101920238,\n  1],\n [0.3626062322946176,\n  0.4111570247933885,\n  0.6079854809437384,\n  0.38626126126126126,\n  0.4575908766928009,\n  0.4173633774980822,\n  0.3077301821762679,\n  0],\n [0.18413597733711043,\n  0.26033057851239666,\n  0.31215970961887474,\n  0.31081081081081063,\n  0.17747683535281542,\n  0.30125212913963256,\n  0.4785819793205316,\n  2],\n [0.07271010387157692,\n  0.1322314049586778,\n  0.27313974591651463,\n  0.15540540540540532,\n  0.08909479686386312,\n  0.426855114485951,\n  0.36632200886262917,\n  2],\n [0.7884796978281399,\n  0.8429752066115699,\n  0.6070780399274045,\n  0.8704954954954958,\n  0.719173200285103,\n  0.5589592895499876,\n  0.9074347612013788,\n  1],\n [0.11709159584513694,\n  0.16942148760330586,\n  0.37658802177858436,\n  0.20495495495495492,\n  0.14967925873129,\n  0.5759924066104097,\n  0.3879862136878387,\n  2],\n [0.898016997167139,\n  0.9462809917355368,\n  0.6034482758620692,\n  0.9470720720720724,\n  0.8232359230220954,\n  0.15471531290226115,\n  0.9502708025603152,\n  1],\n [0.348441926345609,\n  0.3636363636363636,\n  0.7831215970961883,\n  0.28040540540540554,\n  0.4761225944404846,\n  0.7697278601984163,\n  0.23732151649433791,\n  0],\n [0.08498583569405102,\n  0.16735537190082656,\n  0.16515426497277677,\n  0.2280405405405407,\n  0.04632929436920878,\n  0.6010869989208025,\n  0.3894633185622844,\n  2],\n [0.07837582625118036,\n  0.0929752066115701,\n  0.5462794918330303,\n  0.06137387387387387,\n  0.15680684248039922,\n  0.2515830396962645,\n  0.04332840965041856,\n  0],\n [0.3068932955618508,\n  0.31611570247933873,\n  0.7931034482758617,\n  0.23930180180180172,\n  0.5338560228082679,\n  0.19424254638598865,\n  0.14081733136386,\n  0],\n [0.6392823418319169,\n  0.6921487603305785,\n  0.6388384754990919,\n  0.7015765765765763,\n  0.6728439059158943,\n  0.35898269383297143,\n  0.7149187592319055,\n  1],\n [0.7705382436260624,\n  0.7789256198347106,\n  0.8330308529945556,\n  0.6824324324324323,\n  0.8831076265146115,\n  0.4450584456955623,\n  0.725258493353028,\n  1],\n [0.7337110481586402,\n  0.8491735537190082,\n  0.3366606170598904,\n  0.9949324324324328,\n  0.6094084105488238,\n  0.5419261724895655,\n  0.9497784342688333,\n  1],\n [0.1539187913125591,\n  0.18801652892561987,\n  0.5181488203266783,\n  0.18299549549549562,\n  0.2401995723449751,\n  0.6116189262635063,\n  0.3456425406203841,\n  2],\n [0.2747875354107649,\n  0.2975206611570247,\n  0.6996370235934661,\n  0.2545045045045045,\n  0.37633642195295786,\n  0.192942308442445,\n  0.32348596750369285,\n  0],\n [0.2030217186024552,\n  0.26033057851239666,\n  0.43829401088929243,\n  0.27927927927927904,\n  0.23235923022095506,\n  0.22609837600280855,\n  0.17232890201870985,\n  0],\n [0.7280453257790369,\n  0.7190082644628101,\n  0.931941923774955,\n  0.6081081081081082,\n  0.8018531717747681,\n  0.26939629952281274,\n  0.7104874446085672,\n  1],\n [0.07176581680830971,\n  0.14669421487603287,\n  0.19056261343012626,\n  0.15596846846846857,\n  0.027084818246614573,\n  0.464431991054363,\n  0.3018217626784833,\n  2],\n [0.4995278564683665,\n  0.5144628099173554,\n  0.8230490018148823,\n  0.40484234234234256,\n  0.6250890947968638,\n  0.0,\n  0.2816346627277204,\n  0],\n [0.5930122757318226,\n  0.6694214876033059,\n  0.514519056261343,\n  0.6981981981981984,\n  0.593727726300784,\n  0.38108673887321387,\n  0.7129492860659772,\n  1],\n [0.7554296506137866,\n  0.7520661157024795,\n  0.8938294010889288,\n  0.6407657657657658,\n  0.8766928011404131,\n  0.6807915848600294,\n  0.6686361398325947,\n  1],\n [0.4268177525967894,\n  0.440082644628099,\n  0.8212341197822136,\n  0.38288288288288275,\n  0.5930149679258732,\n  0.3072332236799335,\n  0.32545544066962073,\n  0],\n [0.10953729933899907,\n  0.2293388429752065,\n  0.0009074410163338386,\n  0.30686936936936937,\n  0.034212401995723465,\n  0.4697629666228921,\n  0.3894633185622844,\n  2],\n [0.8111425873465533,\n  0.8719008264462808,\n  0.5771324863883849,\n  0.8277027027027026,\n  0.7491090520313612,\n  0.3370086725870835,\n  0.841949778434269,\n  1],\n [0.16713881019830024,\n  0.1611570247933883,\n  0.7640653357531758,\n  0.09966216216216195,\n  0.2936564504632928,\n  0.31919541276053526,\n  0.04234367306745461,\n  0],\n [0.5269121813031163,\n  0.6136363636363638,\n  0.46007259528130656,\n  0.4859234234234232,\n  0.5395580898075552,\n  0.45780077754229026,\n  0.582964057114722,\n  1],\n [0.5703493862134088,\n  0.6301652892561985,\n  0.6043557168784031,\n  0.6497747747747749,\n  0.5951532430506056,\n  0.16576733542238234,\n  0.6686361398325947,\n  0],\n [0.5495750708215298,\n  0.5867768595041322,\n  0.7123411978221419,\n  0.4611486486486487,\n  0.63791874554526,\n  0.44882913573183897,\n  0.5411127523387496,\n  1],\n [0.018885741265344598,\n  0.10743801652892554,\n  0.02359346642468182,\n  0.23536036036036048,\n  0.012829650748396459,\n  0.6107087597030256,\n  0.33234859675036926,\n  2],\n [0.6978281397544854,\n  0.7107438016528925,\n  0.8275862068965515,\n  0.6081081081081082,\n  0.7533856022808265,\n  0.19398249879727994,\n  0.6893156080748398,\n  1],\n [0.6298394711992448,\n  0.6859504132231405,\n  0.6188747731397455,\n  0.6075450450450449,\n  0.6870990734141124,\n  0.49069679751394507,\n  0.6262924667651405,\n  1],\n [0.9556185080264401,\n  0.9958677685950414,\n  0.6188747731397455,\n  0.9459459459459459,\n  0.8439059158945116,\n  0.4792547036107608,\n  0.9512555391432791,\n  1],\n [0.3966005665722379,\n  0.4359504132231404,\n  0.6696914700544465,\n  0.36373873873873874,\n  0.4711332858161082,\n  0.25210313487368197,\n  0.2914820285573608,\n  0],\n [0.6572237960339944,\n  0.6714876033057852,\n  0.8257713248638838,\n  0.5022522522522525,\n  0.7555238774055593,\n  0.5982264754450064,\n  0.5622845888724765,\n  1],\n [0.06421152030217184,\n  0.11570247933884308,\n  0.3067150635208707,\n  0.10641891891891896,\n  0.09479686386315037,\n  0.4607913248124408,\n  0.23682914820285572,\n  2],\n [0.9036827195467423,\n  0.9545454545454548,\n  0.593466424682396,\n  0.9087837837837838,\n  0.8146828225231646,\n  0.1488642421563146,\n  0.8202855736090594,\n  1],\n [0.7252124645892352,\n  0.7603305785123966,\n  0.7159709618874772,\n  0.7173423423423424,\n  0.7277263007840339,\n  0.2181669245471922,\n  0.826193993106844,\n  1],\n [0.19924457034938617,\n  0.2066115702479339,\n  0.7196007259528127,\n  0.15990990990990983,\n  0.3285816108339274,\n  1.0,\n  0.23682914820285572,\n  2],\n [0.5835694050991501,\n  0.6632231404958676,\n  0.5054446460980035,\n  0.5788288288288287,\n  0.5759087669280114,\n  0.5402358631629588,\n  0.6282619399310684,\n  1],\n [0.41548630783758267,\n  0.4442148760330579,\n  0.7277676950998182,\n  0.3778153153153155,\n  0.5324305060584459,\n  0.2851291786396911,\n  0.32299359921221066,\n  0],\n [0.5288007554296508,\n  0.5681818181818182,\n  0.6969147005444647,\n  0.525900900900901,\n  0.5637918745545257,\n  0.017930281241467193,\n  0.3879862136878387,\n  0],\n [0.25967894239848915,\n  0.318181818181818,\n  0.4891107078039924,\n  0.275900900900901,\n  0.3164647184604418,\n  0.6800114420939032,\n  0.3879862136878387,\n  2],\n [0.7799811142587348,\n  0.7768595041322317,\n  0.8847549909255894,\n  0.7055180180180182,\n  0.8382038488952244,\n  0.2701764422889389,\n  0.8276710979812901,\n  1],\n [0.15297450424929188,\n  0.21900826446281002,\n  0.33756805807622525,\n  0.257882882882883,\n  0.18745545260156793,\n  0.11648831736207728,\n  0.3244707040866568,\n  2],\n [0.5882908404154864,\n  0.640495867768595,\n  0.6397459165154268,\n  0.6295045045045048,\n  0.6101211689237349,\n  0.4211340675343588,\n  0.6509108813392419,\n  1],\n [0.8083097261567516,\n  0.8347107438016528,\n  0.7341197822141561,\n  0.757882882882883,\n  0.8446186742694224,\n  0.30151217672834135,\n  0.8202855736090594,\n  1],\n [0.06137865911237019,\n  0.12190082644628096,\n  0.25226860254083433,\n  0.10754504504504496,\n  0.06058446186742689,\n  0.3583325748611996,\n  0.2801575578532743,\n  2],\n [0.1425873465533522,\n  0.15289256198347112,\n  0.6460980036297637,\n  0.11599099099099124,\n  0.2216678545972914,\n  0.1867011663134354,\n  0.26440177252584934,\n  2],\n [1.0,\n  0.9917355371900828,\n  0.8239564428312162,\n  0.9425675675675679,\n  1.0,\n  0.6520563263077144,\n  0.8429345150172329,\n  1],\n [0.14353163361661941,\n  0.21900826446281002,\n  0.28221415607985406,\n  0.1463963963963963,\n  0.28652886671418387,\n  0.09581453405973295,\n  0.0,\n  0],\n [0.25779036827195473,\n  0.31611570247933873,\n  0.4827586206896545,\n  0.36148648648648674,\n  0.31575196008553097,\n  0.8152361882224448,\n  0.4534711964549485,\n  2],\n [0.05571293673276675,\n  0.06404958677685961,\n  0.5435571687840288,\n  0.06193693693693712,\n  0.128296507483963,\n  0.4272451858690141,\n  0.15214180206794692,\n  2],\n [0.8064211520302171,\n  0.8057851239669419,\n  0.8656987295825768,\n  0.7229729729729729,\n  0.9066286528866713,\n  0.17473897723283363,\n  0.6917774495322504,\n  1],\n [0.3654390934844194,\n  0.4008264462809916,\n  0.6687840290381126,\n  0.2753378378378378,\n  0.5324305060584459,\n  0.2648454667204099,\n  0.25849335302806475,\n  0],\n [0.4523135033050048,\n  0.46487603305785125,\n  0.82486388384755,\n  0.3254504504504506,\n  0.5951532430506056,\n  0.36860445461519464,\n  0.4529788281634663,\n  1],\n [0.07743153918791315,\n  0.11157024793388412,\n  0.43466424682395605,\n  0.10754504504504496,\n  0.10334996436208123,\n  0.5450467435540703,\n  0.15066469719350079,\n  2],\n [0.8829084041548633,\n  0.9318181818181822,\n  0.6088929219600723,\n  1.0,\n  0.8075552387740553,\n  0.32335617417987494,\n  1.0,\n  1],\n [0.4192634560906515,\n  0.48760330578512384,\n  0.5235934664246823,\n  0.45213963963963966,\n  0.4148253741981469,\n  0.15185478942646505,\n  0.4529788281634663,\n  0],\n [0.2625118035882908,\n  0.28305785123966926,\n  0.6969147005444647,\n  0.23704954954954974,\n  0.35495367070563083,\n  0.5077299145743671,\n  0.2816346627277204,\n  2],\n [0.3493862134088762,\n  0.3471074380165289,\n  0.8793103448275864,\n  0.22072072072072094,\n  0.50392017106201,\n  0.25145301590191005,\n  0.15066469719350079,\n  0],\n [0.4730878186968838,\n  0.5578512396694214,\n  0.45281306715063485,\n  0.5253378378378378,\n  0.4675694939415538,\n  0.25483363455512364,\n  0.6070901033973412,\n  1],\n [0.1916902738432483,\n  0.26033057851239666,\n  0.36297640653357477,\n  0.2877252252252253,\n  0.20028510334996438,\n  0.33037745907501076,\n  0.3505662235352043,\n  2],\n [0.3871576959395656,\n  0.4297520661157025,\n  0.6515426497277677,\n  0.3738738738738738,\n  0.4483250178189592,\n  0.3667841214942335,\n  0.34465780403742013,\n  0],\n [0.3578847969782815,\n  0.37190082644628114,\n  0.7894736842105262,\n  0.2742117117117118,\n  0.48610121168923714,\n  0.22063737663992516,\n  0.21516494337764666,\n  0],\n [0.021718602455146407,\n  0.08677685950413222,\n  0.1588021778584389,\n  0.15822072072072058,\n  0.0,\n  0.5315242689412162,\n  0.2806499261447565,\n  2],\n [0.7677053824362605,\n  0.7809917355371904,\n  0.8130671506352091,\n  0.623310810810811,\n  0.8745545260156806,\n  0.592765476082123,\n  0.6696208764155587,\n  1],\n [0.22946175637393765,\n  0.2789256198347107,\n  0.5081669691470051,\n  0.27927927927927904,\n  0.2822523164647183,\n  0.3390890532967534,\n  0.15066469719350079,\n  0],\n [0.13408876298394712,\n  0.2293388429752065,\n  0.152450090744101,\n  0.28490990990991005,\n  0.10406272273699206,\n  0.809645165065207,\n  0.36976858690300324,\n  2],\n [0.4523135033050048,\n  0.48760330578512384,\n  0.7041742286751363,\n  0.4296171171171171,\n  0.5623663578047041,\n  0.1604363598538533,\n  0.34613490891186627,\n  0],\n [0.2171860245514637,\n  0.28099173553719,\n  0.41742286751361113,\n  0.33558558558558566,\n  0.2822523164647183,\n  0.7047159630212328,\n  0.39241752831117666,\n  2],\n [0.3569405099150141,\n  0.40909090909090917,\n  0.5852994555353904,\n  0.37725225225225223,\n  0.3727726300784034,\n  0.09087362987426699,\n  0.3845396356474642,\n  0],\n [0.980169971671388,\n  1.0,\n  0.705989110707804,\n  0.9369369369369369,\n  0.9700641482537418,\n  0.5086400811348477,\n  0.8847858197932053,\n  1],\n [0.08404154863078381,\n  0.1322314049586778,\n  0.35571687840290406,\n  0.15822072072072058,\n  0.09123307198859591,\n  0.6645386105657336,\n  0.23781388478581966,\n  2],\n [0.4409820585457979,\n  0.5020661157024793,\n  0.570780399274047,\n  0.48648648648648646,\n  0.48610121168923714,\n  0.18930164220052273,\n  0.3451501723289019,\n  0],\n [0.05665722379603396,\n  0.1322314049586778,\n  0.15607985480943737,\n  0.19763513513513514,\n  0.03207412687099067,\n  0.6563471115214085,\n  0.34465780403742013,\n  2],\n [0.7422096317280453,\n  0.7665289256198349,\n  0.762250453720508,\n  0.6801801801801803,\n  0.8118317890235209,\n  0.19112197532148384,\n  0.6277695716395862,\n  1],\n [0.7677053824362605,\n  0.8119834710743802,\n  0.6615245009074409,\n  0.7432432432432435,\n  0.751247327156094,\n  0.18501085698682865,\n  0.7769571639586413,\n  1],\n [0.33238904627006605,\n  0.34917355371900816,\n  0.7531760435571687,\n  0.29335585585585583,\n  0.47897362794012827,\n  0.2515830396962645,\n  0.23682914820285572,\n  0],\n [0.509915014164306,\n  0.5123966942148761,\n  0.8920145190562611,\n  0.26126126126126153,\n  0.6785459729151815,\n  0.33427817290564177,\n  0.3077301821762679,\n  1],\n [0.4173748819641171,\n  0.48553719008264457,\n  0.5226860254083485,\n  0.501126126126126,\n  0.4383464005702067,\n  0.13339141062814497,\n  0.23732151649433791,\n  0],\n [0.35316336166194523,\n  0.3863636363636362,\n  0.6805807622504535,\n  0.3406531531531529,\n  0.4055595153243049,\n  0.33323798255080683,\n  0.3471196454948302,\n  0],\n [0.7922568460812087,\n  0.859504132231405,\n  0.5499092558983667,\n  0.8727477477477478,\n  0.6571632216678545,\n  0.1792898100352365,\n  0.9522402757262435,\n  1],\n [0.1746931067044381,\n  0.24380165289256192,\n  0.3457350272232298,\n  0.23648648648648649,\n  0.19030648610121156,\n  0.5407559583403764,\n  0.36976858690300324,\n  2],\n [0.91123701605288,\n  0.9297520661157025,\n  0.740471869328494,\n  0.7972972972972976,\n  0.9493941553813257,\n  0.6677892054245927,\n  0.8217626784835056,\n  1],\n [0.7998111425873464,\n  0.8347107438016528,\n  0.7014519056261338,\n  0.854166666666667,\n  0.7761938702779755,\n  0.19281228464809066,\n  0.8094534711964552,\n  1],\n [0.14353163361661941,\n  0.17768595041322302,\n  0.5063520871143373,\n  0.18975225225225212,\n  0.24590163934426235,\n  0.43777711321171775,\n  0.24273756770063984,\n  2],\n [0.7610953729933899,\n  0.8264462809917356,\n  0.5598911070780399,\n  0.7804054054054056,\n  0.6870990734141124,\n  0.4714532759494988,\n  0.7794190054160515,\n  1],\n [0.24268177525967896,\n  0.2913223140495868,\n  0.5272232304900176,\n  0.3124999999999999,\n  0.24590163934426235,\n  0.011702141491893013,\n  0.26440177252584934,\n  0],\n [0.2162417374881965,\n  0.2252066115702479,\n  0.7241379310344829,\n  0.13513513513513528,\n  0.34853884533143276,\n  0.20633475926094477,\n  0.04332840965041856,\n  0],\n [0.3210576015108593,\n  0.2933884297520661,\n  1.0,\n  0.12387387387387375,\n  0.5367070563079115,\n  0.5810633345902301,\n  0.12900049236829128,\n  0],\n [0.20868744098205863,\n  0.21900826446281002,\n  0.7068965517241379,\n  0.14695945945945954,\n  0.35352815395580883,\n  0.5341247448283036,\n  0.1944854751354011,\n  2],\n [0.15108593012275728,\n  0.16322314049586759,\n  0.6370235934664242,\n  0.13400900900900878,\n  0.2501781895937276,\n  0.37263519224018,\n  0.17282127031019204,\n  2],\n [0.05854579792256855,\n  0.14876033057851254,\n  0.07803992740471818,\n  0.21396396396396392,\n  0.04062722736992154,\n  0.702635582311563,\n  0.37223042836041376,\n  2],\n [0.4211520302171861,\n  0.46900826446280985,\n  0.6333938294010889,\n  0.4577702702702702,\n  0.49750534568781163,\n  0.17733945311992097,\n  0.4140817331363862,\n  0]]"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00047-caec7203-8506-4252-ba8f-80d30ca1b3cc","deepnote_to_be_reexecuted":false,"source_hash":"d1feabdd","execution_millis":1,"execution_start":1612396856278,"deepnote_cell_type":"code"},"source":"def split_train_test_set(dataset, train_set_percentage = 0.8): \n    split = int(len(dataset) * train_set_percentage)\n    return (dataset[:split], dataset[split:])","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00048-b1af6b5d-1aa1-440c-bd86-76396ca7c941","deepnote_to_be_reexecuted":false,"source_hash":"f48403b","execution_millis":6,"execution_start":1612396856279,"deepnote_cell_type":"code"},"source":"train_set, test_set = split_train_test_set(normalized_dataset)\nlen(train_set), len(test_set)","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"(168, 42)"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00049-7635dc3d-5818-45a8-9749-fcbac507ba83","deepnote_to_be_reexecuted":false,"source_hash":"fac1bee3","execution_millis":5,"execution_start":1612396856280,"deepnote_cell_type":"code"},"source":"train_set[:3]","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"[[0.408876298394712,\n  0.4173553719008264,\n  0.8393829401088925,\n  0.2730855855855858,\n  0.5573770491803277,\n  0.04900596809216086,\n  0.2801575578532743,\n  0],\n [0.7922568460812087,\n  0.878099173553719,\n  0.4618874773139742,\n  0.9290540540540544,\n  0.7412687099073412,\n  0.380436619901442,\n  0.9743968488429348,\n  1],\n [0.7884796978281399,\n  0.8078512396694215,\n  0.7813067150635207,\n  0.7010135135135136,\n  0.8517462580185317,\n  0.27862798892197277,\n  0.7040866568193008,\n  1]]"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Exercise 18 : Initialize network","metadata":{"tags":[],"cell_id":"00049-ce48e922-9cfd-44db-a040-3acf33eb4727","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00050-bd964730-fff3-4a1c-9a7c-f5dbe0fbba23","deepnote_to_be_reexecuted":false,"source_hash":"9fc870c0","execution_millis":8,"execution_start":1612396856282,"deepnote_cell_type":"code"},"source":"n_inputs = len(train_set[0]) - 1\nn_outputs = len(set([row[-1] for row in train_set]))\nseed_network = init_network(n_inputs, 4, n_outputs)\n\nn_inputs, n_outputs","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"(7, 3)"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00051-c1a731d7-bd45-4d99-8901-e6cdf1570662","deepnote_to_be_reexecuted":false,"source_hash":"13cfaa37","execution_millis":3277,"execution_start":1612396856316,"deepnote_cell_type":"code"},"source":"train_network(seed_network, train_set, 2, 500, n_outputs)","execution_count":null,"outputs":[{"name":"stdout","text":"> epoch=0, lrate=2.000, error=113.448\n> epoch=1, lrate=2.000, error=67.660\n> epoch=2, lrate=2.000, error=50.436\n> epoch=3, lrate=2.000, error=37.101\n> epoch=4, lrate=2.000, error=30.736\n> epoch=5, lrate=2.000, error=27.057\n> epoch=6, lrate=2.000, error=24.370\n> epoch=7, lrate=2.000, error=22.664\n> epoch=8, lrate=2.000, error=21.488\n> epoch=9, lrate=2.000, error=20.483\n> epoch=10, lrate=2.000, error=19.612\n> epoch=11, lrate=2.000, error=18.868\n> epoch=12, lrate=2.000, error=18.144\n> epoch=13, lrate=2.000, error=17.462\n> epoch=14, lrate=2.000, error=16.863\n> epoch=15, lrate=2.000, error=16.295\n> epoch=16, lrate=2.000, error=16.008\n> epoch=17, lrate=2.000, error=15.670\n> epoch=18, lrate=2.000, error=14.865\n> epoch=19, lrate=2.000, error=13.961\n> epoch=20, lrate=2.000, error=13.619\n> epoch=21, lrate=2.000, error=13.281\n> epoch=22, lrate=2.000, error=12.990\n> epoch=23, lrate=2.000, error=12.694\n> epoch=24, lrate=2.000, error=12.467\n> epoch=25, lrate=2.000, error=12.401\n> epoch=26, lrate=2.000, error=12.366\n> epoch=27, lrate=2.000, error=12.299\n> epoch=28, lrate=2.000, error=12.262\n> epoch=29, lrate=2.000, error=12.265\n> epoch=30, lrate=2.000, error=12.270\n> epoch=31, lrate=2.000, error=12.246\n> epoch=32, lrate=2.000, error=12.214\n> epoch=33, lrate=2.000, error=12.187\n> epoch=34, lrate=2.000, error=12.181\n> epoch=35, lrate=2.000, error=11.951\n> epoch=36, lrate=2.000, error=10.998\n> epoch=37, lrate=2.000, error=10.912\n> epoch=38, lrate=2.000, error=10.882\n> epoch=39, lrate=2.000, error=10.890\n> epoch=40, lrate=2.000, error=11.008\n> epoch=41, lrate=2.000, error=11.298\n> epoch=42, lrate=2.000, error=11.832\n> epoch=43, lrate=2.000, error=13.344\n> epoch=44, lrate=2.000, error=13.461\n> epoch=45, lrate=2.000, error=13.605\n> epoch=46, lrate=2.000, error=13.290\n> epoch=47, lrate=2.000, error=13.010\n> epoch=48, lrate=2.000, error=12.029\n> epoch=49, lrate=2.000, error=12.571\n> epoch=50, lrate=2.000, error=12.016\n> epoch=51, lrate=2.000, error=11.746\n> epoch=52, lrate=2.000, error=11.383\n> epoch=53, lrate=2.000, error=11.340\n> epoch=54, lrate=2.000, error=11.272\n> epoch=55, lrate=2.000, error=11.237\n> epoch=56, lrate=2.000, error=11.189\n> epoch=57, lrate=2.000, error=11.157\n> epoch=58, lrate=2.000, error=11.124\n> epoch=59, lrate=2.000, error=11.105\n> epoch=60, lrate=2.000, error=11.129\n> epoch=61, lrate=2.000, error=11.264\n> epoch=62, lrate=2.000, error=12.731\n> epoch=63, lrate=2.000, error=13.324\n> epoch=64, lrate=2.000, error=11.946\n> epoch=65, lrate=2.000, error=11.546\n> epoch=66, lrate=2.000, error=12.065\n> epoch=67, lrate=2.000, error=11.980\n> epoch=68, lrate=2.000, error=11.300\n> epoch=69, lrate=2.000, error=11.898\n> epoch=70, lrate=2.000, error=10.836\n> epoch=71, lrate=2.000, error=11.856\n> epoch=72, lrate=2.000, error=11.804\n> epoch=73, lrate=2.000, error=11.458\n> epoch=74, lrate=2.000, error=12.077\n> epoch=75, lrate=2.000, error=11.874\n> epoch=76, lrate=2.000, error=11.555\n> epoch=77, lrate=2.000, error=11.406\n> epoch=78, lrate=2.000, error=11.484\n> epoch=79, lrate=2.000, error=11.412\n> epoch=80, lrate=2.000, error=11.357\n> epoch=81, lrate=2.000, error=11.331\n> epoch=82, lrate=2.000, error=11.313\n> epoch=83, lrate=2.000, error=11.297\n> epoch=84, lrate=2.000, error=11.288\n> epoch=85, lrate=2.000, error=11.295\n> epoch=86, lrate=2.000, error=11.321\n> epoch=87, lrate=2.000, error=11.370\n> epoch=88, lrate=2.000, error=11.470\n> epoch=89, lrate=2.000, error=11.720\n> epoch=90, lrate=2.000, error=11.758\n> epoch=91, lrate=2.000, error=13.019\n> epoch=92, lrate=2.000, error=12.257\n> epoch=93, lrate=2.000, error=12.546\n> epoch=94, lrate=2.000, error=12.081\n> epoch=95, lrate=2.000, error=15.728\n> epoch=96, lrate=2.000, error=11.043\n> epoch=97, lrate=2.000, error=11.765\n> epoch=98, lrate=2.000, error=13.295\n> epoch=99, lrate=2.000, error=10.626\n> epoch=100, lrate=2.000, error=10.017\n> epoch=101, lrate=2.000, error=14.883\n> epoch=102, lrate=2.000, error=12.986\n> epoch=103, lrate=2.000, error=12.529\n> epoch=104, lrate=2.000, error=9.107\n> epoch=105, lrate=2.000, error=10.637\n> epoch=106, lrate=2.000, error=11.768\n> epoch=107, lrate=2.000, error=12.593\n> epoch=108, lrate=2.000, error=9.127\n> epoch=109, lrate=2.000, error=10.300\n> epoch=110, lrate=2.000, error=11.851\n> epoch=111, lrate=2.000, error=8.221\n> epoch=112, lrate=2.000, error=9.970\n> epoch=113, lrate=2.000, error=13.067\n> epoch=114, lrate=2.000, error=14.869\n> epoch=115, lrate=2.000, error=7.558\n> epoch=116, lrate=2.000, error=9.853\n> epoch=117, lrate=2.000, error=11.036\n> epoch=118, lrate=2.000, error=9.889\n> epoch=119, lrate=2.000, error=10.055\n> epoch=120, lrate=2.000, error=7.856\n> epoch=121, lrate=2.000, error=12.082\n> epoch=122, lrate=2.000, error=9.323\n> epoch=123, lrate=2.000, error=7.409\n> epoch=124, lrate=2.000, error=15.829\n> epoch=125, lrate=2.000, error=9.909\n> epoch=126, lrate=2.000, error=8.098\n> epoch=127, lrate=2.000, error=10.701\n> epoch=128, lrate=2.000, error=7.493\n> epoch=129, lrate=2.000, error=12.261\n> epoch=130, lrate=2.000, error=13.047\n> epoch=131, lrate=2.000, error=6.985\n> epoch=132, lrate=2.000, error=9.658\n> epoch=133, lrate=2.000, error=10.460\n> epoch=134, lrate=2.000, error=9.525\n> epoch=135, lrate=2.000, error=9.756\n> epoch=136, lrate=2.000, error=6.031\n> epoch=137, lrate=2.000, error=14.752\n> epoch=138, lrate=2.000, error=7.843\n> epoch=139, lrate=2.000, error=7.236\n> epoch=140, lrate=2.000, error=8.941\n> epoch=141, lrate=2.000, error=7.928\n> epoch=142, lrate=2.000, error=9.952\n> epoch=143, lrate=2.000, error=7.839\n> epoch=144, lrate=2.000, error=9.763\n> epoch=145, lrate=2.000, error=14.792\n> epoch=146, lrate=2.000, error=7.846\n> epoch=147, lrate=2.000, error=6.361\n> epoch=148, lrate=2.000, error=6.553\n> epoch=149, lrate=2.000, error=6.449\n> epoch=150, lrate=2.000, error=6.791\n> epoch=151, lrate=2.000, error=6.423\n> epoch=152, lrate=2.000, error=13.577\n> epoch=153, lrate=2.000, error=7.364\n> epoch=154, lrate=2.000, error=6.453\n> epoch=155, lrate=2.000, error=7.322\n> epoch=156, lrate=2.000, error=8.388\n> epoch=157, lrate=2.000, error=5.346\n> epoch=158, lrate=2.000, error=9.190\n> epoch=159, lrate=2.000, error=5.061\n> epoch=160, lrate=2.000, error=7.201\n> epoch=161, lrate=2.000, error=7.768\n> epoch=162, lrate=2.000, error=5.979\n> epoch=163, lrate=2.000, error=8.276\n> epoch=164, lrate=2.000, error=5.244\n> epoch=165, lrate=2.000, error=7.694\n> epoch=166, lrate=2.000, error=5.139\n> epoch=167, lrate=2.000, error=8.612\n> epoch=168, lrate=2.000, error=4.842\n> epoch=169, lrate=2.000, error=8.631\n> epoch=170, lrate=2.000, error=5.427\n> epoch=171, lrate=2.000, error=7.950\n> epoch=172, lrate=2.000, error=6.616\n> epoch=173, lrate=2.000, error=10.408\n> epoch=174, lrate=2.000, error=5.199\n> epoch=175, lrate=2.000, error=9.083\n> epoch=176, lrate=2.000, error=5.484\n> epoch=177, lrate=2.000, error=8.490\n> epoch=178, lrate=2.000, error=5.905\n> epoch=179, lrate=2.000, error=7.278\n> epoch=180, lrate=2.000, error=7.441\n> epoch=181, lrate=2.000, error=5.377\n> epoch=182, lrate=2.000, error=8.601\n> epoch=183, lrate=2.000, error=12.945\n> epoch=184, lrate=2.000, error=7.933\n> epoch=185, lrate=2.000, error=7.340\n> epoch=186, lrate=2.000, error=11.132\n> epoch=187, lrate=2.000, error=4.907\n> epoch=188, lrate=2.000, error=6.882\n> epoch=189, lrate=2.000, error=9.528\n> epoch=190, lrate=2.000, error=10.527\n> epoch=191, lrate=2.000, error=4.832\n> epoch=192, lrate=2.000, error=6.733\n> epoch=193, lrate=2.000, error=4.976\n> epoch=194, lrate=2.000, error=6.734\n> epoch=195, lrate=2.000, error=4.950\n> epoch=196, lrate=2.000, error=5.951\n> epoch=197, lrate=2.000, error=6.711\n> epoch=198, lrate=2.000, error=5.106\n> epoch=199, lrate=2.000, error=5.429\n> epoch=200, lrate=2.000, error=6.675\n> epoch=201, lrate=2.000, error=5.122\n> epoch=202, lrate=2.000, error=5.091\n> epoch=203, lrate=2.000, error=4.965\n> epoch=204, lrate=2.000, error=4.884\n> epoch=205, lrate=2.000, error=4.871\n> epoch=206, lrate=2.000, error=4.854\n> epoch=207, lrate=2.000, error=4.841\n> epoch=208, lrate=2.000, error=4.829\n> epoch=209, lrate=2.000, error=4.818\n> epoch=210, lrate=2.000, error=4.808\n> epoch=211, lrate=2.000, error=4.800\n> epoch=212, lrate=2.000, error=4.792\n> epoch=213, lrate=2.000, error=4.785\n> epoch=214, lrate=2.000, error=4.779\n> epoch=215, lrate=2.000, error=4.774\n> epoch=216, lrate=2.000, error=4.770\n> epoch=217, lrate=2.000, error=4.769\n> epoch=218, lrate=2.000, error=4.769\n> epoch=219, lrate=2.000, error=4.773\n> epoch=220, lrate=2.000, error=4.782\n> epoch=221, lrate=2.000, error=4.796\n> epoch=222, lrate=2.000, error=4.818\n> epoch=223, lrate=2.000, error=4.846\n> epoch=224, lrate=2.000, error=4.871\n> epoch=225, lrate=2.000, error=4.885\n> epoch=226, lrate=2.000, error=4.893\n> epoch=227, lrate=2.000, error=4.898\n> epoch=228, lrate=2.000, error=4.896\n> epoch=229, lrate=2.000, error=4.888\n> epoch=230, lrate=2.000, error=4.865\n> epoch=231, lrate=2.000, error=4.745\n> epoch=232, lrate=2.000, error=4.720\n> epoch=233, lrate=2.000, error=4.745\n> epoch=234, lrate=2.000, error=4.749\n> epoch=235, lrate=2.000, error=4.868\n> epoch=236, lrate=2.000, error=5.196\n> epoch=237, lrate=2.000, error=4.933\n> epoch=238, lrate=2.000, error=4.864\n> epoch=239, lrate=2.000, error=5.181\n> epoch=240, lrate=2.000, error=4.800\n> epoch=241, lrate=2.000, error=5.332\n> epoch=242, lrate=2.000, error=4.642\n> epoch=243, lrate=2.000, error=5.418\n> epoch=244, lrate=2.000, error=4.550\n> epoch=245, lrate=2.000, error=5.317\n> epoch=246, lrate=2.000, error=4.607\n> epoch=247, lrate=2.000, error=5.433\n> epoch=248, lrate=2.000, error=4.565\n> epoch=249, lrate=2.000, error=5.342\n> epoch=250, lrate=2.000, error=4.556\n> epoch=251, lrate=2.000, error=5.375\n> epoch=252, lrate=2.000, error=4.551\n> epoch=253, lrate=2.000, error=5.326\n> epoch=254, lrate=2.000, error=4.551\n> epoch=255, lrate=2.000, error=5.318\n> epoch=256, lrate=2.000, error=4.552\n> epoch=257, lrate=2.000, error=5.278\n> epoch=258, lrate=2.000, error=4.565\n> epoch=259, lrate=2.000, error=5.249\n> epoch=260, lrate=2.000, error=4.582\n> epoch=261, lrate=2.000, error=5.203\n> epoch=262, lrate=2.000, error=4.617\n> epoch=263, lrate=2.000, error=5.158\n> epoch=264, lrate=2.000, error=4.661\n> epoch=265, lrate=2.000, error=5.099\n> epoch=266, lrate=2.000, error=4.721\n> epoch=267, lrate=2.000, error=5.030\n> epoch=268, lrate=2.000, error=4.785\n> epoch=269, lrate=2.000, error=4.946\n> epoch=270, lrate=2.000, error=4.832\n> epoch=271, lrate=2.000, error=4.866\n> epoch=272, lrate=2.000, error=4.826\n> epoch=273, lrate=2.000, error=4.805\n> epoch=274, lrate=2.000, error=4.773\n> epoch=275, lrate=2.000, error=4.737\n> epoch=276, lrate=2.000, error=4.695\n> epoch=277, lrate=2.000, error=4.644\n> epoch=278, lrate=2.000, error=4.588\n> epoch=279, lrate=2.000, error=4.539\n> epoch=280, lrate=2.000, error=4.533\n> epoch=281, lrate=2.000, error=4.513\n> epoch=282, lrate=2.000, error=4.250\n> epoch=283, lrate=2.000, error=3.930\n> epoch=284, lrate=2.000, error=3.744\n> epoch=285, lrate=2.000, error=3.694\n> epoch=286, lrate=2.000, error=3.648\n> epoch=287, lrate=2.000, error=3.617\n> epoch=288, lrate=2.000, error=3.593\n> epoch=289, lrate=2.000, error=3.575\n> epoch=290, lrate=2.000, error=3.560\n> epoch=291, lrate=2.000, error=3.548\n> epoch=292, lrate=2.000, error=3.538\n> epoch=293, lrate=2.000, error=3.528\n> epoch=294, lrate=2.000, error=3.520\n> epoch=295, lrate=2.000, error=3.513\n> epoch=296, lrate=2.000, error=3.507\n> epoch=297, lrate=2.000, error=3.501\n> epoch=298, lrate=2.000, error=3.496\n> epoch=299, lrate=2.000, error=3.491\n> epoch=300, lrate=2.000, error=3.486\n> epoch=301, lrate=2.000, error=3.482\n> epoch=302, lrate=2.000, error=3.478\n> epoch=303, lrate=2.000, error=3.474\n> epoch=304, lrate=2.000, error=3.471\n> epoch=305, lrate=2.000, error=3.467\n> epoch=306, lrate=2.000, error=3.464\n> epoch=307, lrate=2.000, error=3.461\n> epoch=308, lrate=2.000, error=3.458\n> epoch=309, lrate=2.000, error=3.455\n> epoch=310, lrate=2.000, error=3.453\n> epoch=311, lrate=2.000, error=3.450\n> epoch=312, lrate=2.000, error=3.447\n> epoch=313, lrate=2.000, error=3.445\n> epoch=314, lrate=2.000, error=3.443\n> epoch=315, lrate=2.000, error=3.440\n> epoch=316, lrate=2.000, error=3.438\n> epoch=317, lrate=2.000, error=3.436\n> epoch=318, lrate=2.000, error=3.434\n> epoch=319, lrate=2.000, error=3.432\n> epoch=320, lrate=2.000, error=3.430\n> epoch=321, lrate=2.000, error=3.428\n> epoch=322, lrate=2.000, error=3.426\n> epoch=323, lrate=2.000, error=3.425\n> epoch=324, lrate=2.000, error=3.423\n> epoch=325, lrate=2.000, error=3.421\n> epoch=326, lrate=2.000, error=3.419\n> epoch=327, lrate=2.000, error=3.418\n> epoch=328, lrate=2.000, error=3.416\n> epoch=329, lrate=2.000, error=3.415\n> epoch=330, lrate=2.000, error=3.413\n> epoch=331, lrate=2.000, error=3.412\n> epoch=332, lrate=2.000, error=3.410\n> epoch=333, lrate=2.000, error=3.409\n> epoch=334, lrate=2.000, error=3.407\n> epoch=335, lrate=2.000, error=3.406\n> epoch=336, lrate=2.000, error=3.404\n> epoch=337, lrate=2.000, error=3.403\n> epoch=338, lrate=2.000, error=3.402\n> epoch=339, lrate=2.000, error=3.400\n> epoch=340, lrate=2.000, error=3.399\n> epoch=341, lrate=2.000, error=3.398\n> epoch=342, lrate=2.000, error=3.397\n> epoch=343, lrate=2.000, error=3.395\n> epoch=344, lrate=2.000, error=3.394\n> epoch=345, lrate=2.000, error=3.393\n> epoch=346, lrate=2.000, error=3.392\n> epoch=347, lrate=2.000, error=3.391\n> epoch=348, lrate=2.000, error=3.389\n> epoch=349, lrate=2.000, error=3.388\n> epoch=350, lrate=2.000, error=3.387\n> epoch=351, lrate=2.000, error=3.386\n> epoch=352, lrate=2.000, error=3.385\n> epoch=353, lrate=2.000, error=3.384\n> epoch=354, lrate=2.000, error=3.383\n> epoch=355, lrate=2.000, error=3.382\n> epoch=356, lrate=2.000, error=3.381\n> epoch=357, lrate=2.000, error=3.380\n> epoch=358, lrate=2.000, error=3.379\n> epoch=359, lrate=2.000, error=3.378\n> epoch=360, lrate=2.000, error=3.377\n> epoch=361, lrate=2.000, error=3.376\n> epoch=362, lrate=2.000, error=3.375\n> epoch=363, lrate=2.000, error=3.374\n> epoch=364, lrate=2.000, error=3.373\n> epoch=365, lrate=2.000, error=3.372\n> epoch=366, lrate=2.000, error=3.371\n> epoch=367, lrate=2.000, error=3.370\n> epoch=368, lrate=2.000, error=3.369\n> epoch=369, lrate=2.000, error=3.368\n> epoch=370, lrate=2.000, error=3.367\n> epoch=371, lrate=2.000, error=3.366\n> epoch=372, lrate=2.000, error=3.365\n> epoch=373, lrate=2.000, error=3.365\n> epoch=374, lrate=2.000, error=3.364\n> epoch=375, lrate=2.000, error=3.363\n> epoch=376, lrate=2.000, error=3.362\n> epoch=377, lrate=2.000, error=3.361\n> epoch=378, lrate=2.000, error=3.360\n> epoch=379, lrate=2.000, error=3.359\n> epoch=380, lrate=2.000, error=3.359\n> epoch=381, lrate=2.000, error=3.358\n> epoch=382, lrate=2.000, error=3.357\n> epoch=383, lrate=2.000, error=3.356\n> epoch=384, lrate=2.000, error=3.355\n> epoch=385, lrate=2.000, error=3.354\n> epoch=386, lrate=2.000, error=3.354\n> epoch=387, lrate=2.000, error=3.353\n> epoch=388, lrate=2.000, error=3.352\n> epoch=389, lrate=2.000, error=3.351\n> epoch=390, lrate=2.000, error=3.351\n> epoch=391, lrate=2.000, error=3.350\n> epoch=392, lrate=2.000, error=3.349\n> epoch=393, lrate=2.000, error=3.348\n> epoch=394, lrate=2.000, error=3.347\n> epoch=395, lrate=2.000, error=3.347\n> epoch=396, lrate=2.000, error=3.346\n> epoch=397, lrate=2.000, error=3.345\n> epoch=398, lrate=2.000, error=3.344\n> epoch=399, lrate=2.000, error=3.344\n> epoch=400, lrate=2.000, error=3.343\n> epoch=401, lrate=2.000, error=3.342\n> epoch=402, lrate=2.000, error=3.341\n> epoch=403, lrate=2.000, error=3.341\n> epoch=404, lrate=2.000, error=3.340\n> epoch=405, lrate=2.000, error=3.339\n> epoch=406, lrate=2.000, error=3.339\n> epoch=407, lrate=2.000, error=3.338\n> epoch=408, lrate=2.000, error=3.337\n> epoch=409, lrate=2.000, error=3.337\n> epoch=410, lrate=2.000, error=3.336\n> epoch=411, lrate=2.000, error=3.335\n> epoch=412, lrate=2.000, error=3.334\n> epoch=413, lrate=2.000, error=3.334\n> epoch=414, lrate=2.000, error=3.333\n> epoch=415, lrate=2.000, error=3.332\n> epoch=416, lrate=2.000, error=3.332\n> epoch=417, lrate=2.000, error=3.331\n> epoch=418, lrate=2.000, error=3.330\n> epoch=419, lrate=2.000, error=3.330\n> epoch=420, lrate=2.000, error=3.329\n> epoch=421, lrate=2.000, error=3.328\n> epoch=422, lrate=2.000, error=3.328\n> epoch=423, lrate=2.000, error=3.327\n> epoch=424, lrate=2.000, error=3.326\n> epoch=425, lrate=2.000, error=3.326\n> epoch=426, lrate=2.000, error=3.325\n> epoch=427, lrate=2.000, error=3.324\n> epoch=428, lrate=2.000, error=3.324\n> epoch=429, lrate=2.000, error=3.323\n> epoch=430, lrate=2.000, error=3.322\n> epoch=431, lrate=2.000, error=3.322\n> epoch=432, lrate=2.000, error=3.321\n> epoch=433, lrate=2.000, error=3.321\n> epoch=434, lrate=2.000, error=3.320\n> epoch=435, lrate=2.000, error=3.319\n> epoch=436, lrate=2.000, error=3.319\n> epoch=437, lrate=2.000, error=3.318\n> epoch=438, lrate=2.000, error=3.317\n> epoch=439, lrate=2.000, error=3.317\n> epoch=440, lrate=2.000, error=3.316\n> epoch=441, lrate=2.000, error=3.316\n> epoch=442, lrate=2.000, error=3.315\n> epoch=443, lrate=2.000, error=3.314\n> epoch=444, lrate=2.000, error=3.314\n> epoch=445, lrate=2.000, error=3.313\n> epoch=446, lrate=2.000, error=3.312\n> epoch=447, lrate=2.000, error=3.312\n> epoch=448, lrate=2.000, error=3.311\n> epoch=449, lrate=2.000, error=3.311\n> epoch=450, lrate=2.000, error=3.310\n> epoch=451, lrate=2.000, error=3.309\n> epoch=452, lrate=2.000, error=3.309\n> epoch=453, lrate=2.000, error=3.308\n> epoch=454, lrate=2.000, error=3.308\n> epoch=455, lrate=2.000, error=3.307\n> epoch=456, lrate=2.000, error=3.307\n> epoch=457, lrate=2.000, error=3.306\n> epoch=458, lrate=2.000, error=3.305\n> epoch=459, lrate=2.000, error=3.305\n> epoch=460, lrate=2.000, error=3.304\n> epoch=461, lrate=2.000, error=3.304\n> epoch=462, lrate=2.000, error=3.303\n> epoch=463, lrate=2.000, error=3.302\n> epoch=464, lrate=2.000, error=3.302\n> epoch=465, lrate=2.000, error=3.301\n> epoch=466, lrate=2.000, error=3.301\n> epoch=467, lrate=2.000, error=3.300\n> epoch=468, lrate=2.000, error=3.300\n> epoch=469, lrate=2.000, error=3.299\n> epoch=470, lrate=2.000, error=3.298\n> epoch=471, lrate=2.000, error=3.298\n> epoch=472, lrate=2.000, error=3.297\n> epoch=473, lrate=2.000, error=3.297\n> epoch=474, lrate=2.000, error=3.296\n> epoch=475, lrate=2.000, error=3.296\n> epoch=476, lrate=2.000, error=3.295\n> epoch=477, lrate=2.000, error=3.295\n> epoch=478, lrate=2.000, error=3.294\n> epoch=479, lrate=2.000, error=3.293\n> epoch=480, lrate=2.000, error=3.293\n> epoch=481, lrate=2.000, error=3.292\n> epoch=482, lrate=2.000, error=3.292\n> epoch=483, lrate=2.000, error=3.291\n> epoch=484, lrate=2.000, error=3.291\n> epoch=485, lrate=2.000, error=3.290\n> epoch=486, lrate=2.000, error=3.290\n> epoch=487, lrate=2.000, error=3.289\n> epoch=488, lrate=2.000, error=3.289\n> epoch=489, lrate=2.000, error=3.288\n> epoch=490, lrate=2.000, error=3.287\n> epoch=491, lrate=2.000, error=3.287\n> epoch=492, lrate=2.000, error=3.286\n> epoch=493, lrate=2.000, error=3.286\n> epoch=494, lrate=2.000, error=3.285\n> epoch=495, lrate=2.000, error=3.285\n> epoch=496, lrate=2.000, error=3.284\n> epoch=497, lrate=2.000, error=3.284\n> epoch=498, lrate=2.000, error=3.283\n> epoch=499, lrate=2.000, error=3.283\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00052-6757f86c-5260-47b6-a2b1-68fd9d347e76","deepnote_to_be_reexecuted":false,"source_hash":"dddba307","execution_millis":18,"execution_start":1612396859603,"deepnote_cell_type":"code"},"source":"for layer in seed_network:\n\tprint(layer)","execution_count":null,"outputs":[{"name":"stdout","text":"[{'weights': [-5.770820437781925, -8.646713130372873, -6.401225276687946, -13.236675050442985, -4.456205218457874, 12.518354780836638, 36.77577262988843, -4.258921270450485], 'output': 0.7187570877257409, 'delta': -3.777591925557755e-07}, {'weights': [12.423755098009897, 10.025270064488765, -3.1187318745936374, -12.35067365242796, 7.895759032933681, 12.092565282891966, 17.716460632735505, -23.065514967568333], 'output': 2.2290815526217296e-07, 'delta': -9.385381483218457e-13}, {'weights': [10.741888622939245, 12.523243245810391, -7.416253188808853, 14.005133953664991, 2.1732883748337515, 2.245604626123859, -13.387246187019187, -3.218776713554402], 'output': 0.0030778568021839225, 'delta': -1.9998352991144653e-09}, {'weights': [6.905873879751171, 7.357686963722843, -3.141294209240534, 5.5986028694432175, 2.495356024131931, -0.2805490194809506, -0.2299326140758385, -7.304968345572325], 'output': 0.0004784990079998191, 'delta': -1.933835871841999e-09}]\n[{'weights': [-12.7219943495794, -15.899716745469078, 9.166281201334638, 0.6980159532128308, 0.9428173156859794], 'output': 0.00028218566408339397, 'delta': -7.960627892276535e-08}, {'weights': [8.291819425330484, 11.450691738597142, -1.3595324615476807, 7.915264405596891, -13.269003183163862], 'output': 0.0006686424069337032, 'delta': -4.4678372991863207e-07}, {'weights': [12.908921785332764, -5.648171299915391, -8.303476096107723, -7.079324567653539, -0.9657885734764532], 'output': 0.9997474489685579, 'delta': 6.37659152666309e-08}]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Exercise 19 : Predict the test set on the trained network","metadata":{"tags":[],"cell_id":"00050-d1305f99-b992-4eb6-99c4-117ac377242e","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00055-ee4a99ee-052c-48e5-bcde-8a33af1f4e44","deepnote_to_be_reexecuted":false,"source_hash":"a721b1d8","execution_millis":5,"execution_start":1612398205571,"deepnote_cell_type":"code"},"source":"count, mse = 0, 0\nfor row in test_set:\n\tprediction = predict(seed_network, row)\n\tif prediction == row[-1]: \n\t\tcount += 1\n\tprint(f'Expected={row[-1]}, Got={prediction}')","execution_count":null,"outputs":[{"name":"stdout","text":"Expected=1, Got=1\nExpected=0, Got=0\nExpected=1, Got=0\nExpected=2, Got=2\nExpected=1, Got=1\nExpected=0, Got=0\nExpected=2, Got=2\nExpected=0, Got=0\nExpected=1, Got=1\nExpected=2, Got=2\nExpected=0, Got=0\nExpected=0, Got=0\nExpected=2, Got=2\nExpected=1, Got=1\nExpected=0, Got=0\nExpected=2, Got=2\nExpected=0, Got=0\nExpected=2, Got=2\nExpected=0, Got=0\nExpected=1, Got=1\nExpected=2, Got=2\nExpected=0, Got=0\nExpected=2, Got=2\nExpected=1, Got=1\nExpected=1, Got=1\nExpected=0, Got=0\nExpected=1, Got=0\nExpected=0, Got=0\nExpected=0, Got=0\nExpected=1, Got=1\nExpected=2, Got=2\nExpected=1, Got=1\nExpected=1, Got=1\nExpected=2, Got=2\nExpected=1, Got=1\nExpected=0, Got=0\nExpected=0, Got=0\nExpected=0, Got=0\nExpected=2, Got=2\nExpected=2, Got=0\nExpected=2, Got=2\nExpected=0, Got=0\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00056-ae2a161c-d3a2-45dd-9340-0978ea64e3cf","deepnote_to_be_reexecuted":false,"source_hash":"6e44b55f","execution_millis":5,"execution_start":1612398210483,"deepnote_cell_type":"code"},"source":"print(f'Accuracy : {count / len(test_set)}')","execution_count":null,"outputs":[{"name":"stdout","text":"Accuracy : 0.9285714285714286\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00057-abd87261-802c-46e8-8e82-c71d51ddfba9","deepnote_to_be_reexecuted":false,"source_hash":"f907fa88","execution_millis":88,"execution_start":1612552824547,"deepnote_cell_type":"code"},"source":"import numpy as np\nMSE = np.square(np.subtract(test_set[-1],prediction)).mean() \nprint(f'Mean Squarred Error: {MSE}')","execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'test_set' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-3a7f5d5ff682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Mean Squarred Error: {MSE}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test_set' is not defined"]}]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=62eda4a8-d26a-4a56-8c6c-5473bb99037f' target=\"_blank\">\n<img style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"003d8ea9-72cb-4aea-91e3-094957eef06f","deepnote_execution_queue":[],"deepnote":{}}}